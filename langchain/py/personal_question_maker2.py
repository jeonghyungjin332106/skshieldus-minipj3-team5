
import os
import json
import logging
from typing import Dict, List, Optional, Any, Annotated, TypedDict
from dataclasses import dataclass, asdict
import gradio as gr
from datetime import datetime
from pathlib import Path

# LangGraph & LangChain imports
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
import operator

# ê¸°ì¡´ imports
import pdfplumber
import docx
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============ ìƒíƒœ ì •ì˜ ============
class InterviewGeneratorState(TypedDict):
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    messages: Annotated[List[BaseMessage], operator.add]
    company_name: str
    position: str
    interview_type: str
    difficulty_level: str
    question_count: int
    user_profile: Dict[str, Any]
    resume_content: str
    generated_questions: str
    generated_files: List[str]
    current_step: str
    is_complete: bool
    error_message: str


# ============ Pydantic ëª¨ë¸ ============
class CompanyInfo(BaseModel):
    """íšŒì‚¬ ì •ë³´"""
    company_name: str = Field(description="ì§€ì›í•  íšŒì‚¬ëª…")
    position: str = Field(description="ì§€ì› ì§ë¬´/í¬ì§€ì…˜")

class InterviewSettings(BaseModel):
    """ë©´ì ‘ ì„¤ì •"""
    interview_type: str = Field(description="ë©´ì ‘ ìœ í˜• (ê¸°ìˆ ë©´ì ‘/ì¸ì„±ë©´ì ‘/ì„ì›ë©´ì ‘/ì¢…í•©ë©´ì ‘)")
    difficulty_level: str = Field(description="ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰)")
    question_count: int = Field(description="ì§ˆë¬¸ ê°œìˆ˜", ge=5, le=30)


# ============ ë„êµ¬ ì •ì˜ ============
@tool
def collect_company_info(company_name: str, position: str) -> Dict[str, str]:
    """íšŒì‚¬ëª…ê³¼ ì§€ì› ì§ë¬´ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    logger.info(f"íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘: {company_name}, {position}")
    return {
        "company_name": company_name,
        "position": position,
        "status": "success"
    }

@tool
def determine_job_type(position: str) -> Dict[str, str]:
    """ì§ë¬´ ìœ í˜•ì„ ë¶„ì„í•˜ì—¬ ì í•©í•œ ë©´ì ‘ ìœ í˜•ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    logger.info(f"ì§ë¬´ ìœ í˜• ë¶„ì„: {position}")
    
    position_lower = position.lower()
    
    # ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ë§¤í•‘
    job_mapping = {
        "ê°œë°œì§": ["ê°œë°œ", "í”„ë¡ íŠ¸", "ë°±ì—”ë“œ", "í’€ìŠ¤íƒ", "developer", "frontend", "backend", "ì—”ì§€ë‹ˆì–´"],
        "ê¸°íšì§": ["ê¸°íš", "pm", "planning", "product", "manager", "ì „ëµ"],
        "ë§ˆì¼€íŒ…ì§": ["ë§ˆì¼€íŒ…", "marketing", "ë¸Œëœë“œ", "brand", "ê´‘ê³ ", "í™ë³´"],
        "ë””ìì¸ì§": ["ë””ìì¸", "design", "ui", "ux", "designer", "ì‹œê°"],
        "ë°ì´í„°ì§": ["ë°ì´í„°", "data", "analyst", "scientist", "ai", "ml", "ë¶„ì„"],
        "ì˜ì—…ì§": ["ì˜ì—…", "sales", "ì„¸ì¼ì¦ˆ", "ê³ ê°", "ë¹„ì¦ˆë‹ˆìŠ¤"],
        "ì¸ì‚¬ì§": ["ì¸ì‚¬", "hr", "ì±„ìš©", "êµìœ¡", "ì¡°ì§"],
        "ì¬ë¬´ì§": ["ì¬ë¬´", "íšŒê³„", "finance", "ê²½ë¦¬", "íˆ¬ì"]
    }
    
    detected_type = "ì¼ë°˜ì§"
    for job_type, keywords in job_mapping.items():
        if any(keyword in position_lower for keyword in keywords):
            detected_type = job_type
            break
    
    # ì§ë¬´ë³„ ì¶”ì²œ ë©´ì ‘ ìœ í˜•
    interview_recommendations = {
        "ê°œë°œì§": {
            "primary": "ê¸°ìˆ ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "ê¸°ìˆ  ì—­ëŸ‰ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ ì¤‘ì‹¬"
        },
        "ê¸°íšì§": {
            "primary": "ì¢…í•©ë©´ì ‘", 
            "secondary": "ì¸ì„±ë©´ì ‘",
            "description": "ë…¼ë¦¬ì  ì‚¬ê³ ì™€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì¤‘ì‹¬"
        },
        "ë§ˆì¼€íŒ…ì§": {
            "primary": "ì¸ì„±ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘", 
            "description": "ì°½ì˜ì„±ê³¼ ì‹œì¥ ì´í•´ë„ ì¤‘ì‹¬"
        },
        "ë””ìì¸ì§": {
            "primary": "ê¸°ìˆ ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "í¬íŠ¸í´ë¦¬ì˜¤ì™€ ì°½ì‘ ê³¼ì • ì¤‘ì‹¬"
        },
        "ë°ì´í„°ì§": {
            "primary": "ê¸°ìˆ ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "ë¶„ì„ ëŠ¥ë ¥ê³¼ í†µê³„ ì§€ì‹ ì¤‘ì‹¬"
        },
        "ì˜ì—…ì§": {
            "primary": "ì¸ì„±ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "ì„¤ë“ë ¥ê³¼ ê³ ê° ì§€í–¥ì„± ì¤‘ì‹¬"
        },
        "ì¸ì‚¬ì§": {
            "primary": "ì¸ì„±ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "ì†Œí†µ ëŠ¥ë ¥ê³¼ ì¡°ì§ ì´í•´ë„ ì¤‘ì‹¬"
        },
        "ì¬ë¬´ì§": {
            "primary": "ê¸°ìˆ ë©´ì ‘",
            "secondary": "ì¢…í•©ë©´ì ‘",
            "description": "ì „ë¬¸ ì§€ì‹ê³¼ ë¶„ì„ ëŠ¥ë ¥ ì¤‘ì‹¬"
        },
        "ì¼ë°˜ì§": {
            "primary": "ì¢…í•©ë©´ì ‘",
            "secondary": "ì¸ì„±ë©´ì ‘",
            "description": "ì „ë°˜ì ì¸ ì—­ëŸ‰ê³¼ ì¡°ì§ ì í•©ì„± ì¤‘ì‹¬"
        }
    }
    
    recommendation = interview_recommendations.get(detected_type, interview_recommendations["ì¼ë°˜ì§"])
    
    return {
        "job_type": detected_type,
        "primary_interview": recommendation["primary"],
        "secondary_interview": recommendation["secondary"],
        "description": recommendation["description"],
        "status": "success"
    }

@tool  
def analyze_resume_content(resume_content: str) -> Dict[str, str]:
    """ì´ë ¥ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    logger.info("ì´ë ¥ì„œ ë¶„ì„ ì‹œì‘")
    
    # ì‹¤ì œ LLM ë¶„ì„ (ê°„ì†Œí™”ëœ ë²„ì „)
    api_key = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.1)
    
    analysis_prompt = f"""
ë‹¤ìŒ ì´ë ¥ì„œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{resume_content[:2000]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "career_level": "ì‹ ì…/ê²½ë ¥",
    "education": "ìµœì¢… í•™ë ¥",
    "major": "ì „ê³µ",
    "tech_stack": "ê¸°ìˆ  ìŠ¤íƒ",
    "summary": "ê°„ë‹¨í•œ ìš”ì•½"
}}
"""
    
    try:
        response = llm.invoke([HumanMessage(content=analysis_prompt)])
        # JSON íŒŒì‹± ì‹œë„
        result_text = response.content.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            result_text = result_text[3:-3]
        
        analysis = json.loads(result_text)
        analysis["status"] = "success"
        return analysis
    except Exception as e:
        logger.error(f"ì´ë ¥ì„œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            "career_level": extract_career_level(resume_content),
            "education": "ëŒ€í•™êµ ì¡¸ì—…",
            "major": "ê´€ë ¨ ì „ê³µ",
            "tech_stack": extract_tech_keywords(resume_content),
            "summary": resume_content[:200] + "...",
            "status": "basic_analysis"
        }

@tool
def set_interview_preferences(interview_type: str, difficulty_level: str, question_count: int) -> Dict[str, Any]:
    """ë©´ì ‘ ì„¤ì •ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    logger.info(f"ë©´ì ‘ ì„¤ì •: {interview_type}, {difficulty_level}, {question_count}")
    
    # ì…ë ¥ê°’ ì •ê·œí™”
    interview_type_mapping = {
        "ê¸°ìˆ ": "ê¸°ìˆ ë©´ì ‘", "ê¸°ìˆ ë©´ì ‘": "ê¸°ìˆ ë©´ì ‘", "tech": "ê¸°ìˆ ë©´ì ‘", "technical": "ê¸°ìˆ ë©´ì ‘",
        "ì¸ì„±": "ì¸ì„±ë©´ì ‘", "ì¸ì„±ë©´ì ‘": "ì¸ì„±ë©´ì ‘", "personality": "ì¸ì„±ë©´ì ‘", "ë¬¸í™”": "ì¸ì„±ë©´ì ‘",
        "ì„ì›": "ì„ì›ë©´ì ‘", "ì„ì›ë©´ì ‘": "ì„ì›ë©´ì ‘", "executive": "ì„ì›ë©´ì ‘", "ê²½ì˜ì§„": "ì„ì›ë©´ì ‘",
        "ì¢…í•©": "ì¢…í•©ë©´ì ‘", "ì¢…í•©ë©´ì ‘": "ì¢…í•©ë©´ì ‘", "comprehensive": "ì¢…í•©ë©´ì ‘", "ì „ì²´": "ì¢…í•©ë©´ì ‘", "ì¼ë°˜": "ì¢…í•©ë©´ì ‘"
    }
    
    difficulty_mapping = {
        "ì´ˆê¸‰": "ì´ˆê¸‰", "ì‰¬ìš´": "ì´ˆê¸‰", "easy": "ì´ˆê¸‰", "beginner": "ì´ˆê¸‰", "ì…ë¬¸": "ì´ˆê¸‰", "ê¸°ì´ˆ": "ì´ˆê¸‰",
        "ì¤‘ê¸‰": "ì¤‘ê¸‰", "ë³´í†µ": "ì¤‘ê¸‰", "medium": "ì¤‘ê¸‰", "intermediate": "ì¤‘ê¸‰", "ì¼ë°˜": "ì¤‘ê¸‰",
        "ê³ ê¸‰": "ê³ ê¸‰", "ì–´ë ¤ìš´": "ê³ ê¸‰", "hard": "ê³ ê¸‰", "advanced": "ê³ ê¸‰", "ë†’ì€": "ê³ ê¸‰", "ì–´ë ¤": "ê³ ê¸‰"
    }
    
    # ì •ê·œí™”ëœ ê°’ ì¶”ì¶œ
    normalized_interview_type = interview_type_mapping.get(interview_type.lower(), "ì¢…í•©ë©´ì ‘")
    normalized_difficulty = difficulty_mapping.get(difficulty_level.lower(), "ì¤‘ê¸‰")
    
    # ì§ˆë¬¸ ê°œìˆ˜ ê²€ì¦ ë° ì¡°ì •
    if question_count < 5:
        question_count = 5
    elif question_count > 30:
        question_count = 30
    
    # ë©´ì ‘ ìœ í˜•ë³„ ì¶”ì²œ ì§ˆë¬¸ ê°œìˆ˜
    recommended_counts = {
        "ê¸°ìˆ ë©´ì ‘": {"ì´ˆê¸‰": 12, "ì¤‘ê¸‰": 15, "ê³ ê¸‰": 18},
        "ì¸ì„±ë©´ì ‘": {"ì´ˆê¸‰": 10, "ì¤‘ê¸‰": 12, "ê³ ê¸‰": 15},
        "ì„ì›ë©´ì ‘": {"ì´ˆê¸‰": 8, "ì¤‘ê¸‰": 10, "ê³ ê¸‰": 12},
        "ì¢…í•©ë©´ì ‘": {"ì´ˆê¸‰": 15, "ì¤‘ê¸‰": 18, "ê³ ê¸‰": 22}
    }
    
    recommended_count = recommended_counts.get(normalized_interview_type, {}).get(normalized_difficulty, 15)
    
    return {
        "interview_type": normalized_interview_type,
        "difficulty_level": normalized_difficulty,
        "question_count": question_count,
        "recommended_count": recommended_count,
        "status": "success"
    }

@tool
def suggest_interview_settings(job_type: str, career_level: str = "", company_size: str = "") -> Dict[str, Any]:
    """ì§ë¬´ì™€ ê²½ë ¥ì— ë”°ë¼ ìµœì ì˜ ë©´ì ‘ ì„¤ì •ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    logger.info(f"ë©´ì ‘ ì„¤ì • ì¶”ì²œ: {job_type}, {career_level}, {company_size}")
    
    # ê²½ë ¥ë³„ ë‚œì´ë„ ë§¤í•‘
    career_difficulty_mapping = {
        "ì‹ ì…": "ì´ˆê¸‰",
        "1ë…„ì°¨": "ì´ˆê¸‰", "2ë…„ì°¨": "ì´ˆê¸‰",
        "3ë…„ì°¨": "ì¤‘ê¸‰", "4ë…„ì°¨": "ì¤‘ê¸‰", "5ë…„ì°¨": "ì¤‘ê¸‰",
        "6ë…„ì°¨": "ê³ ê¸‰", "7ë…„ì°¨": "ê³ ê¸‰", "8ë…„ì°¨": "ê³ ê¸‰", "9ë…„ì°¨": "ê³ ê¸‰", "10ë…„ì°¨": "ê³ ê¸‰",
        "ì‹œë‹ˆì–´": "ê³ ê¸‰", "ë¦¬ë“œ": "ê³ ê¸‰", "ë§¤ë‹ˆì €": "ê³ ê¸‰", "íŒ€ì¥": "ê³ ê¸‰"
    }
    
    # ê¸°ë³¸ ì¶”ì²œ ì„¤ì •
    suggestions = {
        "ê°œë°œì§": {
            "ì‹ ì…": {"type": "ê¸°ìˆ ë©´ì ‘", "difficulty": "ì´ˆê¸‰", "count": 12},
            "ê²½ë ¥": {"type": "ê¸°ìˆ ë©´ì ‘", "difficulty": "ì¤‘ê¸‰", "count": 15},
            "ì‹œë‹ˆì–´": {"type": "ì¢…í•©ë©´ì ‘", "difficulty": "ê³ ê¸‰", "count": 18}
        },
        "ê¸°íšì§": {
            "ì‹ ì…": {"type": "ì¸ì„±ë©´ì ‘", "difficulty": "ì´ˆê¸‰", "count": 10},
            "ê²½ë ¥": {"type": "ì¢…í•©ë©´ì ‘", "difficulty": "ì¤‘ê¸‰", "count": 15},
            "ì‹œë‹ˆì–´": {"type": "ì„ì›ë©´ì ‘", "difficulty": "ê³ ê¸‰", "count": 12}
        },
        "ë§ˆì¼€íŒ…ì§": {
            "ì‹ ì…": {"type": "ì¸ì„±ë©´ì ‘", "difficulty": "ì´ˆê¸‰", "count": 10},
            "ê²½ë ¥": {"type": "ì¢…í•©ë©´ì ‘", "difficulty": "ì¤‘ê¸‰", "count": 15},
            "ì‹œë‹ˆì–´": {"type": "ì„ì›ë©´ì ‘", "difficulty": "ê³ ê¸‰", "count": 12}
        },
        "ë””ìì¸ì§": {
            "ì‹ ì…": {"type": "ê¸°ìˆ ë©´ì ‘", "difficulty": "ì´ˆê¸‰", "count": 10},
            "ê²½ë ¥": {"type": "ê¸°ìˆ ë©´ì ‘", "difficulty": "ì¤‘ê¸‰", "count": 12},
            "ì‹œë‹ˆì–´": {"type": "ì¢…í•©ë©´ì ‘", "difficulty": "ê³ ê¸‰", "count": 15}
        }
    }
    
    # ê²½ë ¥ ìˆ˜ì¤€ ê²°ì •
    if any(keyword in career_level.lower() for keyword in ["ì‹ ì…", "new", "junior", "ì¡¸ì—…ì˜ˆì •"]):
        career_category = "ì‹ ì…"
    elif any(keyword in career_level.lower() for keyword in ["ì‹œë‹ˆì–´", "senior", "ë¦¬ë“œ", "lead", "íŒ€ì¥", "ë§¤ë‹ˆì €"]):
        career_category = "ì‹œë‹ˆì–´"
    else:
        career_category = "ê²½ë ¥"
    
    # ì¶”ì²œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    job_suggestions = suggestions.get(job_type, suggestions.get("ê°œë°œì§"))
    recommended = job_suggestions.get(career_category, job_suggestions["ê²½ë ¥"])
    
    # íšŒì‚¬ ê·œëª¨ì— ë”°ë¥¸ ì¡°ì •
    if "ëŒ€ê¸°ì—…" in company_size or "ê¸€ë¡œë²Œ" in company_size:
        recommended["difficulty"] = "ê³ ê¸‰" if recommended["difficulty"] != "ê³ ê¸‰" else "ê³ ê¸‰"
        recommended["count"] += 3
    elif "ìŠ¤íƒ€íŠ¸ì—…" in company_size or "ì¤‘ì†Œê¸°ì—…" in company_size:
        if recommended["type"] == "ì„ì›ë©´ì ‘":
            recommended["type"] = "ì¢…í•©ë©´ì ‘"
    
    return {
        "recommended_interview_type": recommended["type"],
        "recommended_difficulty": recommended["difficulty"],
        "recommended_count": min(recommended["count"], 30),
        "career_category": career_category,
        "reasoning": f"{job_type} {career_category}ì—ê²Œ ìµœì í™”ëœ ì„¤ì •ì…ë‹ˆë‹¤.",
        "status": "success"
    }

@tool
def generate_interview_questions(
    company_name: str,
    position: str,
    interview_type: str,
    difficulty_level: str,
    question_count: int,
    user_profile_json: str
) -> Dict[str, str]:
    """ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì‹œì‘")
    
    try:
        user_profile = json.loads(user_profile_json) if user_profile_json else {}
    except:
        user_profile = {}
    
    api_key = os.getenv("OPENAI_API_KEY")
    llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.7)
    
    prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ {interview_type} ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

[ì§€ì›ì ì •ë³´]
- íšŒì‚¬: {company_name}
- ì§ë¬´: {position}
- ê²½ë ¥: {user_profile.get('career_level', 'ì •ë³´ ì—†ìŒ')}
- í•™ë ¥: {user_profile.get('education', 'ì •ë³´ ì—†ìŒ')}
- ì „ê³µ: {user_profile.get('major', 'ì •ë³´ ì—†ìŒ')}
- ê¸°ìˆ ìŠ¤íƒ: {user_profile.get('tech_stack', 'ì •ë³´ ì—†ìŒ')}
- ë©´ì ‘ìœ í˜•: {interview_type}
- ë‚œì´ë„: {difficulty_level}
- ì§ˆë¬¸ê°œìˆ˜: {question_count}ê°œ

ì¡°ê±´:
1. ê°œì¸í™”ëœ ì§ˆë¬¸ (ì§€ì›ìì˜ ë°°ê²½ í™œìš©)
2. {position} ì§ë¬´ì— íŠ¹í™”
3. {difficulty_level} ìˆ˜ì¤€ì˜ ë‚œì´ë„
4. ì‹¤ìš©ì ì´ê³  í˜„ì‹¤ì ì¸ ì§ˆë¬¸

ê° ì§ˆë¬¸ë§ˆë‹¤ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±:

### ì§ˆë¬¸ [ë²ˆí˜¸]: [ì§ˆë¬¸ ë‚´ìš©]
**ì§ˆë¬¸ ì˜ë„**: [í‰ê°€ ëª©ì ]
**ë‹µë³€ ê°€ì´ë“œ**: [ë‹µë³€ ë°©í–¥]
**ì˜ˆìƒ ì‹œê°„**: [ì†Œìš” ì‹œê°„]

---

ì´ {question_count}ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
    
    try:
        response = llm.invoke([HumanMessage(content=prompt)])
        questions = response.content
        
        return {
            "questions": questions,
            "status": "success"
        }
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            "questions": f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "status": "error"
        }

@tool
def save_questions_to_file(questions: str, company_name: str, position: str) -> Dict[str, str]:
    """ìƒì„±ëœ ì§ˆë¬¸ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    logger.info("íŒŒì¼ ì €ì¥ ì‹œì‘")
    
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"ë©´ì ‘ì§ˆë¬¸_{company_name}_{position}_{timestamp}.txt"
        safe_filename = "".join(c for c in filename if c.isalnum() or c in "._- ").strip()
        
        temp_dir = Path("temp_downloads")
        temp_dir.mkdir(exist_ok=True)
        
        file_path = temp_dir / safe_filename
        
        content = f"""
# {company_name} - {position} ë©´ì ‘ ì§ˆë¬¸

ìƒì„± ì‹œê°„: {datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")}

{questions}

---
ë³¸ ì§ˆë¬¸ì€ AIê°€ ìƒì„±í•œ ê²ƒìœ¼ë¡œ, ì‹¤ì œ ë©´ì ‘ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return {
            "file_path": str(file_path),
            "status": "success"
        }
    except Exception as e:
        logger.error(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return {
            "file_path": "",
            "status": "error",
            "error": str(e)
        }


# ============ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ============
def extract_career_level(text: str) -> str:
    """ê²½ë ¥ ìˆ˜ì¤€ ì¶”ì¶œ"""
    text_lower = text.lower()
    if any(word in text_lower for word in ["ì‹ ì…", "new", "junior", "ì¡¸ì—…"]):
        return "ì‹ ì…"
    elif any(word in text_lower for word in ["ë…„", "year", "ê²½ë ¥", "experience"]):
        return "ê²½ë ¥"
    return "ì‹ ì…"

def extract_tech_keywords(text: str) -> str:
    """ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ"""
    tech_keywords = [
        "Python", "Java", "JavaScript", "React", "Vue", "Angular",
        "Spring", "Django", "Flask", "Node.js", "AWS", "Docker",
        "Kubernetes", "Git", "SQL", "MongoDB", "Redis", "TypeScript"
    ]
    
    found_techs = [tech for tech in tech_keywords if tech.lower() in text.lower()]
    return ", ".join(found_techs) if found_techs else "ê¸°ë³¸ ê¸°ìˆ  ìŠ¤íƒ"

def process_uploaded_file(file_path: str) -> str:
    """íŒŒì¼ ì²˜ë¦¬"""
    try:
        _, ext = os.path.splitext(file_path)
        ext = ext.lower()
        
        if ext == '.pdf':
            with pdfplumber.open(file_path) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                return text
                
        elif ext == '.docx':
            doc = docx.Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        text += cell.text + " "
            return text
            
        elif ext == '.txt':
            encodings = ['utf-8', 'cp949', 'euc-kr']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        return f.read()
                except UnicodeDecodeError:
                    continue
            raise ValueError("ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        else:
            raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")
            
    except Exception as e:
        raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


# ============ LangGraph ë…¸ë“œ ì •ì˜ ============
def chatbot_node(state: InterviewGeneratorState) -> InterviewGeneratorState:
    """ë©”ì¸ ì±—ë´‡ ë…¸ë“œ - ë„êµ¬ ë°”ì¸ë”©ëœ LLM"""
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    tools = [
        collect_company_info,
        determine_job_type,
        analyze_resume_content,
        suggest_interview_settings,
        set_interview_preferences,
        generate_interview_questions,
        save_questions_to_file
    ]
    
    llm_with_tools = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.3
    ).bind_tools(tools)
    
    system_message = """
ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìˆ˜ì§‘í•  ì •ë³´:
1. íšŒì‚¬ëª…ê³¼ ì§€ì› ì§ë¬´ (collect_company_info ì‚¬ìš©)
2. ì´ë ¥ì„œ/ê²½ë ¥ ì •ë³´ (analyze_resume_content ì‚¬ìš©)
3. ë©´ì ‘ ì„¤ì • (set_interview_preferences ì‚¬ìš©)
4. ì§ˆë¬¸ ìƒì„± (generate_interview_questions ì‚¬ìš©)
5. íŒŒì¼ ì €ì¥ (save_questions_to_file ì‚¬ìš©)

ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•˜ê³ , ì ì ˆí•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•´ì£¼ì„¸ìš”.
"""
    
    messages = [SystemMessage(content=system_message)] + state["messages"]
    
    try:
        response = llm_with_tools.invoke(messages)
        return {
            **state,
            "messages": [response],
        }
    except Exception as e:
        logger.error(f"ì±—ë´‡ ë…¸ë“œ ì˜¤ë¥˜: {str(e)}")
        error_response = AIMessage(content=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return {
            **state,
            "messages": [error_response],
            "error_message": str(e)
        }

def tools_node(state: InterviewGeneratorState) -> InterviewGeneratorState:
    """ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ"""
    
    last_message = state["messages"][-1]
    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:
        return state
    
    tools = [
        collect_company_info,
        determine_job_type,
        analyze_resume_content,
        suggest_interview_settings,
        set_interview_preferences,
        generate_interview_questions,
        save_questions_to_file
    ]
    
    tool_node = ToolNode(tools)
    tool_messages = tool_node.invoke({"messages": [last_message]})
    
    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ìƒíƒœì— ë°˜ì˜
    updated_state = state.copy()
    
    for message in tool_messages["messages"]:
        if hasattr(message, 'name') and hasattr(message, 'content'):
            tool_name = message.name
            try:
                content = json.loads(message.content) if message.content.startswith('{') else {"result": message.content}
            except:
                content = {"result": message.content}
            
            # ë„êµ¬ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸
            if tool_name == "collect_company_info" and content.get("status") == "success":
                updated_state["company_name"] = content.get("company_name", "")
                updated_state["position"] = content.get("position", "")
                
            elif tool_name == "determine_job_type" and content.get("status") == "success":
                if "user_profile" not in updated_state:
                    updated_state["user_profile"] = {}
                updated_state["user_profile"]["job_type"] = content.get("job_type", "")
                updated_state["user_profile"]["primary_interview"] = content.get("primary_interview", "")
                updated_state["user_profile"]["secondary_interview"] = content.get("secondary_interview", "")
                updated_state["user_profile"]["job_description"] = content.get("description", "")
                
            elif tool_name == "analyze_resume_content" and content.get("status") in ["success", "basic_analysis"]:
                if "user_profile" not in updated_state:
                    updated_state["user_profile"] = {}
                updated_state["user_profile"]["career_level"] = content.get("career_level", "")
                updated_state["user_profile"]["education"] = content.get("education", "")
                updated_state["user_profile"]["major"] = content.get("major", "")
                updated_state["user_profile"]["tech_stack"] = content.get("tech_stack", "")
                updated_state["user_profile"]["summary"] = content.get("summary", "")
                
            elif tool_name == "suggest_interview_settings" and content.get("status") == "success":
                if "user_profile" not in updated_state:
                    updated_state["user_profile"] = {}
                updated_state["user_profile"]["recommended_interview_type"] = content.get("recommended_interview_type", "")
                updated_state["user_profile"]["recommended_difficulty"] = content.get("recommended_difficulty", "")
                updated_state["user_profile"]["recommended_count"] = content.get("recommended_count", 15)
                updated_state["user_profile"]["career_category"] = content.get("career_category", "")
                updated_state["user_profile"]["reasoning"] = content.get("reasoning", "")
                
            elif tool_name == "set_interview_preferences" and content.get("status") == "success":
                updated_state["interview_type"] = content.get("interview_type", "")
                updated_state["difficulty_level"] = content.get("difficulty_level", "")
                updated_state["question_count"] = content.get("question_count", 15)
                
            elif tool_name == "generate_interview_questions":
                if content.get("status") == "success":
                    updated_state["generated_questions"] = content.get("questions", "")
                    updated_state["is_complete"] = True
                else:
                    updated_state["error_message"] = content.get("questions", "")
                    
            elif tool_name == "save_questions_to_file" and content.get("status") == "success":
                file_path = content.get("file_path", "")
                if file_path:
                    updated_state["generated_files"] = updated_state.get("generated_files", []) + [file_path]
    
    updated_state["messages"] = tool_messages["messages"]
    return updated_state

def should_continue(state: InterviewGeneratorState) -> str:
    """ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    
    # ë©”ì‹œì§€ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not state.get("messages"):
        return END
    
    last_message = state["messages"][-1]
    
    # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ ë„êµ¬ ë…¸ë“œë¡œ
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    
    # ì´ë¯¸ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ
    if state.get("is_complete", False):
        return END
    
    # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
    if state.get("error_message"):
        return END
    
    # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì¢…ë£Œ (ë¬´í•œë£¨í”„ ë°©ì§€)
    return END


# ============ LangGraph ì›Œí¬í”Œë¡œìš° ============
def create_workflow() -> StateGraph:
    """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    
    workflow = StateGraph(InterviewGeneratorState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("chatbot", chatbot_node)
    workflow.add_node("tools", tools_node)
    
    # ì—£ì§€ ì¶”ê°€ - ë¬´í•œë£¨í”„ ë°©ì§€
    workflow.add_edge(START, "chatbot")
    workflow.add_conditional_edges(
        "chatbot",
        should_continue,
        {"tools": "tools", END: END}  # "chatbot": "chatbot" ì œê±°ë¡œ ë¬´í•œë£¨í”„ ë°©ì§€
    )
    workflow.add_edge("tools", "chatbot")  # ë„êµ¬ ì‹¤í–‰ í›„ í•œ ë²ˆë§Œ ì±—ë´‡ìœ¼ë¡œ
    
    # recursion_limit ì„¤ì •
    return workflow.compile(debug=False)


# ============ ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤ ============
class LangGraphInterviewGenerator:
    """LangGraph ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        self.workflow = create_workflow()
        self.reset_conversation()
    
    def reset_conversation(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        self.state = {
            "messages": [],
            "company_name": "",
            "position": "",
            "interview_type": "",
            "difficulty_level": "",
            "question_count": 15,
            "user_profile": {},
            "resume_content": "",
            "generated_questions": "",
            "generated_files": [],
            "current_step": "start",
            "is_complete": False,
            "error_message": ""
        }
    
    def chat(self, message: str, history: List, files=None) -> tuple:
        """ë©”ì¸ ì±„íŒ… ì²˜ë¦¬"""
        try:
            logger.info(f"ì±„íŒ… ì²˜ë¦¬ ì‹œì‘: {message}")
            
            # íŒŒì¼ ì²˜ë¦¬
            if files:
                file_path = files.name if hasattr(files, 'name') else str(files)
                try:
                    resume_content = process_uploaded_file(file_path)
                    self.state["resume_content"] = resume_content
                    message += f"\n\n[ì´ë ¥ì„œ ì—…ë¡œë“œë¨]\n{resume_content[:500]}..."
                    logger.info("íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    error_msg = f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}\nì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”."
                    history.append(["[íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨]", error_msg])
                    return history, ""
            
            # ì´ˆê¸°í™” ëª…ë ¹ì–´ ì²´í¬
            if any(cmd in message.lower() for cmd in ["ì²˜ìŒë¶€í„°", "ì´ˆê¸°í™”", "ë¦¬ì…‹", "ë‹¤ì‹œ"]):
                self.reset_conversation()
                welcome_msg = "ì•ˆë…•í•˜ì„¸ìš”! ë©´ì ‘ ì¤€ë¹„ë¥¼ ë„ì™€ë“œë¦´ê²Œìš” ğŸ˜Š\n\nì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”?"
                history.append([message, welcome_msg])
                return history, ""
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            human_message = HumanMessage(content=message)
            self.state["messages"] = [human_message]
            
            logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì „ ìƒíƒœ: {self.state.keys()}")
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (recursion_limit ì„¤ì •)
            config = {"recursion_limit": 10}  # ìµœëŒ€ 10ë²ˆ ë°˜ë³µìœ¼ë¡œ ì œí•œ
            result = self.workflow.invoke(self.state, config=config)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸ - ì—¬ê¸°ê°€ í•µì‹¬!
            self.state.update(result)
            logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í›„ ìƒíƒœ: company={self.state.get('company_name')}, position={self.state.get('position')}")
            
            # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ì¶œ
            response_content = ""
            if result.get("messages"):
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content') and last_message.content:
                    response_content = last_message.content
                else:
                    response_content = "ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."
                
                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í¬ë§·íŒ…
                if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                    tool_info = self._format_tool_info(last_message.tool_calls)
                    if tool_info:
                        response_content += f"\n\n{tool_info}"
            else:
                response_content = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            history.append([message, response_content])
            
            return history, ""
            
        except Exception as e:
            logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            history.append([message, error_msg])
            return history, ""
    
    def _format_tool_info(self, tool_calls) -> str:
        """ë„êµ¬ í˜¸ì¶œ ì •ë³´ í¬ë§·íŒ…"""
        info_parts = []
        
        for tool_call in tool_calls:
            tool_name = tool_call.get("name", "")
            
            if tool_name == "collect_company_info":
                info_parts.append("âœ… íšŒì‚¬ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "determine_job_type":
                info_parts.append("ğŸ¯ ì§ë¬´ ë¶„ì„ ì™„ë£Œ! ìµœì ì˜ ë©´ì ‘ ìœ í˜•ì„ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "analyze_resume_content":
                info_parts.append("ğŸ“‹ ì´ë ¥ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "suggest_interview_settings":
                info_parts.append("ğŸ’¡ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì„¤ì •ì„ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "set_interview_preferences":
                info_parts.append("âš™ï¸ ë©´ì ‘ ì„¤ì •ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "generate_interview_questions":
                info_parts.append("ğŸ¯ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif tool_name == "save_questions_to_file":
                info_parts.append("ğŸ’¾ íŒŒì¼ ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        return "\n".join(info_parts) if info_parts else ""
    
    def get_download_files(self) -> List[str]:
        """ë‹¤ìš´ë¡œë“œ íŒŒì¼ ëª©ë¡"""
        return self.state.get("generated_files", [])
    
    def get_collected_info(self) -> Dict:
        """ìˆ˜ì§‘ëœ ì •ë³´"""
        return {
            "company_name": self.state.get("company_name", ""),
            "position": self.state.get("position", ""),
            "interview_type": self.state.get("interview_type", ""),
            "difficulty_level": self.state.get("difficulty_level", ""),
            "question_count": self.state.get("question_count", 0),
            "user_profile": self.state.get("user_profile", {}),
            "is_complete": self.state.get("is_complete", False)
        }
    
    def create_interface(self):
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        
        with gr.Blocks(
            title="LangGraph ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°",
            theme=gr.themes.Soft(),
            css="""
            .chat-container { max-height: 600px; overflow-y: auto; }
            .info-panel { background-color: #f8f9fa; padding: 15px; border-radius: 8px; }
            """
        ) as demo:
            
            gr.Markdown("""
            # ğŸš€ LangGraph ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°
            
            **ì²´ê³„ì ì¸ ì›Œí¬í”Œë¡œìš°ì™€ ìƒíƒœ ê´€ë¦¬ë¡œ ë”ìš± ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤**
            
            âœ¨ **LangGraph íŠ¹ì§•:**
            - ğŸ”„ **ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°**: ì²´ê³„ì ì¸ ëŒ€í™” íë¦„ ê´€ë¦¬
            - ğŸ› ï¸ **ë„êµ¬ ìë™ ì‹¤í–‰**: í•„ìš”ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ ì„ íƒ
            - ğŸ¯ **ì¡°ê±´ë¶€ ë¼ìš°íŒ…**: ìƒí™©ì— ë§ëŠ” ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
            - ğŸ’¾ **ìƒíƒœ ìœ ì§€**: ëŒ€í™” ì¤‘ ì •ë³´ ëˆ„ì  ë° ê´€ë¦¬
            
            ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”! ì‹œìŠ¤í…œì´ ì•Œì•„ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
                    chatbot = gr.Chatbot(
                        value=[[None, "ì•ˆë…•í•˜ì„¸ìš”! LangGraph ê¸°ë°˜ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤ ğŸ¤–\n\nì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”?"]],
                        label="ğŸ¯ ë©´ì ‘ ì¤€ë¹„ ëŒ€í™”",
                        height=500,
                        elem_classes=["chat-container"]
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            label="ğŸ’¬ ë©”ì‹œì§€",
                            placeholder="ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”... (ì˜ˆ: ë„¤ì´ë²„ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œ ì§€ì›í•´ìš”)",
                            scale=3
                        )
                        file_upload = gr.File(
                            label="ğŸ“ ì´ë ¥ì„œ",
                            file_types=[".pdf", ".docx", ".txt"],
                            scale=1
                        )
                    
                    with gr.Row():
                        send_btn = gr.Button("ğŸ“¤ ì „ì†¡", variant="primary", scale=2)
                        clear_btn = gr.Button("ğŸ”„ ì´ˆê¸°í™”", scale=1)
                
                with gr.Column(scale=1):
                    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ í‘œì‹œ
                    gr.Markdown("### ğŸ”„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ")
                    workflow_status = gr.JSON(
                        label="ğŸ“Š ìˆ˜ì§‘ëœ ì •ë³´",
                        value={},
                        elem_classes=["info-panel"]
                    )
                    
                    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
                    gr.Markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                    download_btn = gr.DownloadButton(
                        "ğŸ“„ ë©´ì ‘ ì§ˆë¬¸ ë‹¤ìš´ë¡œë“œ",
                        visible=False,
                        variant="secondary"
                    )
                    
                    download_status = gr.Markdown(
                        "ì§ˆë¬¸ì´ ìƒì„±ë˜ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.",
                        elem_classes=["info-panel"]
                    )
            
            # LangGraph ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ (ì •ë³´ìš©)
            gr.Markdown("""
            ### ğŸ§  LangGraph ì›Œí¬í”Œë¡œìš°
            
            ```
            START â†’ ì±—ë´‡ ë…¸ë“œ â†’ ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ â†’ ì±—ë´‡ ë…¸ë“œ â†’ ... â†’ END
                      â†“           â†“               â†‘
                   ë„êµ¬ í•„ìš”?    ë„êµ¬ ì‹¤í–‰        ê²°ê³¼ ë°˜ì˜
                      â†“           â†“               â†‘
                   [íšŒì‚¬ì •ë³´]   [ì´ë ¥ì„œë¶„ì„]    [ì„¤ì •ì €ì¥]
                   [ì§ˆë¬¸ìƒì„±]   [íŒŒì¼ì €ì¥]      [ì™„ë£Œí™•ì¸]
            ```
            
            **ë…¸ë“œë³„ ì—­í• :**
            - ğŸ¤– **ì±—ë´‡ ë…¸ë“œ**: ì‚¬ìš©ìì™€ ëŒ€í™”, ë„êµ¬ í˜¸ì¶œ ê²°ì •
            - ğŸ› ï¸ **ë„êµ¬ ë…¸ë“œ**: ì •ë³´ ìˆ˜ì§‘, ë¶„ì„, ì§ˆë¬¸ ìƒì„±, íŒŒì¼ ì €ì¥
            - ğŸ”€ **ì¡°ê±´ë¶€ ë¼ìš°íŒ…**: ë‹¤ìŒ ë‹¨ê³„ ìë™ ê²°ì •
            """)
            
            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
            def send_message(message, history, files):
                new_history, _ = self.chat(message, history, files)
                collected_info = self.get_collected_info()
                
                # ë‹¤ìš´ë¡œë“œ íŒŒì¼ í™•ì¸
                download_files = self.get_download_files()
                download_file = download_files[0] if download_files else None
                
                # ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                status_info = self.get_collected_info()
                if status_info.get("is_complete"):
                    status_msg = "âœ… ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ! ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
                elif status_info.get("company_name") and status_info.get("position"):
                    status_msg = "ğŸ”„ ì •ë³´ ìˆ˜ì§‘ ì¤‘... ê³„ì† ëŒ€í™”í•´ì£¼ì„¸ìš”."
                else:
                    status_msg = "ì§ˆë¬¸ì´ ìƒì„±ë˜ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
                
                logger.info(f"UI ì—…ë°ì´íŠ¸: collected_info={collected_info}")
                
                return (
                    new_history, "", collected_info,
                    gr.update(value=download_file, visible=bool(download_file)),
                    status_msg
                )
            
            def clear_chat():
                self.reset_conversation()
                return (
                    [[None, "ì•ˆë…•í•˜ì„¸ìš”! LangGraph ê¸°ë°˜ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤ ğŸ¤–\n\nì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”?"]],
                    "", {},
                    gr.update(visible=False),
                    "ì§ˆë¬¸ì´ ìƒì„±ë˜ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
                )
            
            # ì´ë²¤íŠ¸ ì—°ê²°
            send_btn.click(
                send_message,
                [msg, chatbot, file_upload],
                [chatbot, msg, workflow_status, download_btn, download_status]
            )
            
            msg.submit(
                send_message,
                [msg, chatbot, file_upload],
                [chatbot, msg, workflow_status, download_btn, download_status]
            )
            
            clear_btn.click(
                clear_chat,
                outputs=[chatbot, msg, workflow_status, download_btn, download_status]
            )
            
            # ì˜ˆì œ ëŒ€í™” ë° ì„¤ëª…
            gr.Markdown("""
            ### ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ
            
            **ğŸ—£ï¸ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ì˜ˆì‹œ:**
            
            **ì‚¬ìš©ì**: "ì•ˆë…•í•˜ì„¸ìš”! ì¹´ì¹´ì˜¤ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œ ì§€ì›í•˜ëŠ”ë° ê¸°ìˆ ë©´ì ‘ ì¤€ë¹„í•˜ê³  ì‹¶ì–´ìš”"
            
            **AI**: "ì¹´ì¹´ì˜¤ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ì§€ì›ì„ ìœ„í•œ ê¸°ìˆ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! 
                   ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì‹œê±°ë‚˜ ê°„ë‹¨í•œ ê²½ë ¥ì‚¬í•­ì„ ì•Œë ¤ì£¼ì„¸ìš”."
            
            **ì‚¬ìš©ì**: [ì´ë ¥ì„œ íŒŒì¼ ì—…ë¡œë“œ] 
            
            **AI**: "ì´ë ¥ì„œ ë¶„ì„ ì™„ë£Œ! React 3ë…„ ê²½í—˜ìì‹œêµ°ìš”. 
                   ì¤‘ê¸‰ ìˆ˜ì¤€ìœ¼ë¡œ 15ê°œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì‹œê² ì–´ìš”?"
            
            **ì‚¬ìš©ì**: "ë„¤, ì¢‹ìŠµë‹ˆë‹¤!"
            
            **AI**: "ì™„ë£Œ! ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”! âœ…"
            
            ### ğŸ¯ LangGraphì˜ ì¥ì 
            
            1. **ğŸ”„ ìƒíƒœ ê´€ë¦¬**: ëŒ€í™” ì¤‘ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ëˆ„ì 
            2. **ğŸ¤– ì§€ëŠ¥ì  ë¼ìš°íŒ…**: ìƒí™©ì— ë§ëŠ” ë‹¤ìŒ ë‹¨ê³„ ìë™ ê²°ì •  
            3. **ğŸ› ï¸ ë„êµ¬ ìë™ ì‹¤í–‰**: í•„ìš”í•  ë•Œ ì ì ˆí•œ ë„êµ¬ ìë™ ì„ íƒ
            4. **ğŸ“Š íˆ¬ëª…ì„±**: í˜„ì¬ ìƒíƒœì™€ ì§„í–‰ ìƒí™©ì„ ëª…í™•íˆ í‘œì‹œ
            5. **ğŸ”§ í™•ì¥ì„±**: ìƒˆë¡œìš´ ë…¸ë“œì™€ ë„êµ¬ë¥¼ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥
            
            ### ğŸ”§ ì§€ì›í•˜ëŠ” ë„êµ¬ë“¤
            
            - **collect_company_info**: íšŒì‚¬ëª…ê³¼ ì§ë¬´ ì •ë³´ ìˆ˜ì§‘
            - **determine_job_type**: ì§ë¬´ ë¶„ì„ ë° ë©´ì ‘ ìœ í˜• ì¶”ì²œ
            - **analyze_resume_content**: ì´ë ¥ì„œ ë‚´ìš© AI ë¶„ì„  
            - **suggest_interview_settings**: ê°œì¸ ë§ì¶¤í˜• ì„¤ì • ì¶”ì²œ
            - **set_interview_preferences**: ìµœì¢… ë©´ì ‘ ì„¤ì • í™•ì •
            - **generate_interview_questions**: ê°œì¸ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
            - **save_questions_to_file**: ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            
            ### ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ
            
            **ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ìë™ ì¶”ì²œ:**
            - ğŸ–¥ï¸ **ê°œë°œì§** â†’ ê¸°ìˆ ë©´ì ‘ ì¶”ì²œ
            - ğŸ“‹ **ê¸°íšì§** â†’ ì¢…í•©ë©´ì ‘ ì¶”ì²œ  
            - ğŸ“ˆ **ë§ˆì¼€íŒ…ì§** â†’ ì¸ì„±ë©´ì ‘ ì¶”ì²œ
            - ğŸ¨ **ë””ìì¸ì§** â†’ ê¸°ìˆ ë©´ì ‘ ì¶”ì²œ
            - ğŸ“Š **ë°ì´í„°ì§** â†’ ê¸°ìˆ ë©´ì ‘ ì¶”ì²œ
            
            **ê²½ë ¥ë³„ ë‚œì´ë„ ìë™ ì¡°ì •:**
            - ğŸ‘¨â€ğŸ“ **ì‹ ì…** â†’ ì´ˆê¸‰ ë‚œì´ë„, 10-12ê°œ ì§ˆë¬¸
            - ğŸ‘©â€ğŸ’¼ **ê²½ë ¥** â†’ ì¤‘ê¸‰ ë‚œì´ë„, 15-18ê°œ ì§ˆë¬¸
            - ğŸ‘¨â€ğŸ’¼ **ì‹œë‹ˆì–´** â†’ ê³ ê¸‰ ë‚œì´ë„, 18-22ê°œ ì§ˆë¬¸
            
            **íšŒì‚¬ ê·œëª¨ë³„ ë§ì¶¤ ì¡°ì •:**
            - ğŸ¢ **ëŒ€ê¸°ì—…** â†’ ë‚œì´ë„ ìƒí–¥, ì§ˆë¬¸ ìˆ˜ ì¦ê°€
            - ğŸš€ **ìŠ¤íƒ€íŠ¸ì—…** â†’ ì‹¤ë¬´ ì¤‘ì‹¬ ì¡°ì •
            
            ### ğŸš€ ê°œì„ ëœ ê¸°ëŠ¥ë“¤
            
            - **ìŠ¤ë§ˆíŠ¸ íŒŒì¼ ì²˜ë¦¬**: PDF, DOCX, TXT ìë™ ì¸ì‹
            - **ì—ëŸ¬ ë³µêµ¬**: ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ ë°©ë²• ìë™ ì œì‹œ
            - **ì‹¤ì‹œê°„ ìƒíƒœ í‘œì‹œ**: í˜„ì¬ ì§„í–‰ ìƒí™© ì‹œê°í™”
            - **ì›í´ë¦­ ë‹¤ìš´ë¡œë“œ**: ìƒì„±ëœ ì§ˆë¬¸ ì¦‰ì‹œ ì €ì¥
            """)
        
        return demo


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ LangGraph ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸° ì‹œì‘...")
        
        # í™˜ê²½ ì„¤ì • í™•ì¸
        if not os.getenv("OPENAI_API_KEY"):
            print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            print("   .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ì¶”ê°€")
            return
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path("temp_downloads")
        temp_dir.mkdir(exist_ok=True)
        print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬: {temp_dir.absolute()}")
        
        # LangGraph ì›Œí¬í”Œë¡œìš° ì¸í„°í˜ì´ìŠ¤ ìƒì„±
        print("ğŸ”„ LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì¤‘...")
        generator = LangGraphInterviewGenerator()
        demo = generator.create_interface()
        
        print("ğŸŒ ì„œë²„ ì‹œì‘ ì¤‘...")
        demo.launch(
            share=False,
            debug=True,
            server_name="127.0.0.1",
            server_port=7860,
            show_error=True
        )
        
    except ImportError as e:
        print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {str(e)}")
        print("pip install langgraph langchain-openai ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        print(f"âŒ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()