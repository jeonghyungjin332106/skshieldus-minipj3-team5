"""
LangGraph ê¸°ë°˜ ëŒ€í™”í˜• ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°
personal_question_maker.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ëŒ€í™”í˜•ìœ¼ë¡œ êµ¬í˜„
"""

import os
import json
import logging
from typing import Dict, List, Optional, Any, Annotated, TypedDict
from dataclasses import dataclass, asdict
import gradio as gr
from datetime import datetime
from pathlib import Path

# LangGraph & LangChain imports
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
import operator

# ê¸°ì¡´ imports (personal_question_maker.pyì—ì„œ)
import pdfplumber
import docx
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ============ ìƒíƒœ ì •ì˜ ============
class InterviewGeneratorState(TypedDict):
    """LangGraph ìƒíƒœ ê´€ë¦¬ - ëª¨ë“  ê°œì¸ í”„ë¡œí•„ ì •ë³´ í¬í•¨"""
    messages: Annotated[List[BaseMessage], operator.add]
    
    # ê¸°ë³¸ ì •ë³´
    company_name: str
    position: str
    career_level: str
    website_url: str
    
    # ê°œì¸ í”„ë¡œí•„ ì •ë³´ (PersonalProfileê³¼ ë™ì¼)
    education_level: str
    major: str
    gpa: str
    certificates: str
    language_skills: str
    tech_stack: str
    personality_type: str
    project_scale: str
    leadership_experience: str
    domain_experience: str
    portfolio_links: str
    blog_activity: str
    sns_activity: str
    open_source: str
    awards: str
    competitions: str
    publications: str
    application_source: str
    priority_values: str
    career_goal: str
    work_style: str
    
    # ë©´ì ‘ ì„¤ì •
    interview_type: str
    difficulty_level: str
    question_count: int
    
    # ë¬¸ì„œ ë° ìƒì„± ê²°ê³¼
    resume_content: str
    company_website_info: str
    generated_questions: str
    generated_files: List[str]
    
    # ì§„í–‰ ìƒíƒœ
    current_step: str
    collected_fields: List[str]
    is_complete: bool
    error_message: str


# ============ ê¸°ì¡´ í´ë˜ìŠ¤ë“¤ (personal_question_maker.pyì—ì„œ) ============
class DocumentProcessor:
    """ë¬¸ì„œ ì²˜ë¦¬ í´ë˜ìŠ¤ - ê¸°ì¡´ê³¼ ë™ì¼"""
    
    @staticmethod
    def extract_pdf_text(file_path: str) -> str:
        """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (pdfplumber ì‚¬ìš©)"""
        try:
            text = ""
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                        
                        # í…Œì´ë¸”ì´ ìˆëŠ” ê²½ìš° í…Œì´ë¸” ë‚´ìš©ë„ ì¶”ì¶œ
                        tables = page.extract_tables()
                        for table in tables:
                            for row in table:
                                if row:  # Noneì´ ì•„ë‹Œ í–‰ë§Œ ì²˜ë¦¬
                                    row_text = " | ".join([cell or "" for cell in row])
                                    text += row_text + "\n"
            
            if not text.strip():
                raise ValueError("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
            return text
        except Exception as e:
            raise Exception(f"PDF íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    @staticmethod
    def extract_docx_text(file_path: str) -> str:
        """DOCX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        try:
            doc = docx.Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            raise Exception(f"DOCX íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    @staticmethod
    def extract_text_from_uploaded_file(file_path: str) -> str:
        """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not file_path or not os.path.exists(file_path):
            raise ValueError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        file_path = os.path.normpath(file_path)
        _, file_extension = os.path.splitext(file_path)
        file_extension = file_extension.lower()
        
        try:
            if file_extension == '.pdf':
                text = DocumentProcessor.extract_pdf_text(file_path)
            elif file_extension == '.docx':
                text = DocumentProcessor.extract_docx_text(file_path)
            elif file_extension == '.txt':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    text = f.read()
            else:
                raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_extension}")
            
            if not text.strip():
                raise ValueError("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text)} ë¬¸ì")
            return text
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise e


class SimpleWebCrawler:
    """ì›¹ í¬ë¡¤ëŸ¬ - ê¸°ì¡´ê³¼ ë™ì¼"""
    
    @staticmethod
    def crawl_company_basic_info(website_url: str) -> str:
        """íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê¸°ë³¸ ì •ë³´ í¬ë¡¤ë§"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(website_url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼ íƒœê·¸ ì œê±°
            for script in soup(["script", "style"]):
                script.extract()
            
            text = soup.get_text()
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = ' '.join(chunk for chunk in chunks if chunk)
            
            # ê¸¸ì´ ì œí•œ (í† í° ì ˆì•½)
            return text[:5000] if len(text) > 5000 else text
            
        except Exception as e:
            return f"ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}"


# ============ LangGraph ë„êµ¬ ì •ì˜ ============
@tool
def collect_basic_info(company_name: str, position: str, website_url: str = "") -> Dict[str, Any]:
    """íšŒì‚¬ëª…, ì§€ì› ì§ë¬´, ì›¹ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    logger.info(f"ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘: {company_name}, {position}")
    
    result = {
        "company_name": company_name.strip(),
        "position": position.strip(),
        "website_url": website_url.strip() if website_url else "",
        "status": "success",
        "message": f"âœ… {company_name} {position} ì§€ì› ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!"
    }
    
    # ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹œë„
    if website_url.strip():
        try:
            company_info = SimpleWebCrawler.crawl_company_basic_info(website_url)
            result["company_website_info"] = company_info
            result["message"] += f"\nğŸŒ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ë„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            result["company_website_info"] = ""
            result["message"] += f"\nâš ï¸ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
    
    return result

@tool
def process_resume_file(file_path: str) -> Dict[str, Any]:
    """ì´ë ¥ì„œ íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ìƒì„¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    logger.info(f"ì´ë ¥ì„œ íŒŒì¼ ì²˜ë¦¬: {file_path}")
    
    try:
        # íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        resume_content = DocumentProcessor.extract_text_from_uploaded_file(file_path)
        
        # AIë¡œ ìƒì„¸ ë¶„ì„
        api_key = os.getenv("OPENAI_API_KEY")
        llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.1)
        
        analysis_prompt = f"""
ë‹¤ìŒ ì´ë ¥ì„œ ë‚´ìš©ì—ì„œ ìƒì„¸í•œ ê°œì¸ í”„ë¡œí•„ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì´ë ¥ì„œ ë‚´ìš©:
{resume_content[:4000]}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "career_level": "ì‹ ì…/ê²½ë ¥ ì¤‘ í•˜ë‚˜",
    "education_level": "ê³ ë“±í•™êµ/ì „ë¬¸í•™ì‚¬/í•™ì‚¬/ì„ì‚¬/ë°•ì‚¬ ì¤‘ í•˜ë‚˜",
    "major": "ì „ê³µëª… ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "gpa": "í•™ì  ì •ë³´ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "certificates": "ìê²©ì¦ë“¤ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "language_skills": "ì–´í•™ ëŠ¥ë ¥ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "tech_stack": "ê¸°ìˆ  ìŠ¤íƒë“¤ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "personality_type": "ì„±ê²© íŠ¹ì„± ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "project_scale": "ê°œì¸ í”„ë¡œì íŠ¸/ì†Œê·œëª¨ íŒ€(2-5ëª…)/ì¤‘ê·œëª¨ íŒ€(6-15ëª…)/ëŒ€ê·œëª¨ íŒ€(16ëª…+) ì¤‘ í•˜ë‚˜",
    "leadership_experience": "ì—†ìŒ/ë¶€ë¶„ì  ë¦¬ë” ì—­í• /íŒ€ ë¦¬ë”/í”„ë¡œì íŠ¸ ë§¤ë‹ˆì € ì¤‘ í•˜ë‚˜",
    "portfolio_links": "í¬íŠ¸í´ë¦¬ì˜¤ ë§í¬ë“¤ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "blog_activity": "ë¸”ë¡œê·¸ í™œë™ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "sns_activity": "SNS í™œë™ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "open_source": "ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "awards": "ìˆ˜ìƒ ê²½ë ¥ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "competitions": "ëŒ€íšŒ ì°¸ì—¬ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
    "publications": "ë°œí‘œ/ì¶œê°„ ê²½ë ¥ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´"
}}

ì°¾ëŠ” ê¸°ì¤€:
- ëª…ì‹œì ìœ¼ë¡œ ê¸°ì¬ëœ ì •ë³´ë§Œ ì¶”ì¶œ
- ì—†ëŠ” ì •ë³´ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
- ì¶”ì¸¡í•˜ì§€ ë§ê³  í™•ì‹¤í•œ ì •ë³´ë§Œ ê¸°ì¬
"""
        
        response = llm.invoke([HumanMessage(content=analysis_prompt)])
        result_text = response.content.strip()
        
        # JSON íŒŒì‹±
        if result_text.startswith("```json"):
            result_text = result_text[7:-3]
        elif result_text.startswith("```"):
            result_text = result_text[3:-3]
        
        profile_data = json.loads(result_text)
        profile_data["resume_content"] = resume_content
        profile_data["status"] = "success"
        profile_data["message"] = "ğŸ“‹ ì´ë ¥ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì¶”ì¶œëœ ì •ë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        return profile_data
        
    except Exception as e:
        logger.error(f"ì´ë ¥ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {
            "status": "error",
            "message": f"âŒ ì´ë ¥ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "resume_content": ""
        }

@tool
def suggest_interview_settings(position: str, career_level: str = "", tech_stack: str = "") -> Dict[str, Any]:
    """ì§ë¬´ì™€ ê²½ë ¥ì— ë”°ë¼ ìµœì ì˜ ë©´ì ‘ ì„¤ì •ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""
    logger.info(f"ë©´ì ‘ ì„¤ì • ì¶”ì²œ: {position}, {career_level}")
    
    position_lower = position.lower()
    
    # ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ë§¤í•‘ (ê¸°ì¡´ê³¼ ë™ì¼)
    job_mapping = {
        "ê°œë°œì§": ["ê°œë°œ", "í”„ë¡ íŠ¸", "ë°±ì—”ë“œ", "í’€ìŠ¤íƒ", "developer", "frontend", "backend", "ì—”ì§€ë‹ˆì–´", "react", "vue", "python", "java"],
        "ê¸°íšì§": ["ê¸°íš", "pm", "planning", "product", "manager", "ì „ëµ"],
        "ë§ˆì¼€íŒ…ì§": ["ë§ˆì¼€íŒ…", "marketing", "ë¸Œëœë“œ", "brand", "ê´‘ê³ ", "í™ë³´"],
        "ë””ìì¸ì§": ["ë””ìì¸", "design", "ui", "ux", "designer", "ì‹œê°"],
        "ë°ì´í„°ì§": ["ë°ì´í„°", "data", "analyst", "scientist", "ai", "ml", "ë¶„ì„"],
        "ì˜ì—…ì§": ["ì˜ì—…", "sales", "ì„¸ì¼ì¦ˆ", "ê³ ê°", "ë¹„ì¦ˆë‹ˆìŠ¤"],
        "ì¸ì‚¬ì§": ["ì¸ì‚¬", "hr", "ì±„ìš©", "êµìœ¡", "ì¡°ì§"],
        "ì¬ë¬´ì§": ["ì¬ë¬´", "íšŒê³„", "finance", "ê²½ë¦¬", "íˆ¬ì"]
    }
    
    detected_type = "ì¼ë°˜ì§"
    for job_type, keywords in job_mapping.items():
        if any(keyword in position_lower for keyword in keywords):
            detected_type = job_type
            break
    
    # ë©´ì ‘ ìœ í˜•ë³„ ì¶”ì²œ
    recommendations = {
        "ê°œë°œì§": {"type": "ê¸°ìˆ ë©´ì ‘", "description": "ê¸°ìˆ  ì—­ëŸ‰ê³¼ ë¬¸ì œí•´ê²° ëŠ¥ë ¥ ì¤‘ì‹¬"},
        "ê¸°íšì§": {"type": "ì¢…í•©ë©´ì ‘", "description": "ë…¼ë¦¬ì  ì‚¬ê³ ì™€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì¤‘ì‹¬"},
        "ë§ˆì¼€íŒ…ì§": {"type": "ì¸ì„±ë©´ì ‘", "description": "ì°½ì˜ì„±ê³¼ ì‹œì¥ ì´í•´ë„ ì¤‘ì‹¬"},
        "ë””ìì¸ì§": {"type": "ê¸°ìˆ ë©´ì ‘", "description": "í¬íŠ¸í´ë¦¬ì˜¤ì™€ ì°½ì‘ ê³¼ì • ì¤‘ì‹¬"},
        "ë°ì´í„°ì§": {"type": "ê¸°ìˆ ë©´ì ‘", "description": "ë¶„ì„ ëŠ¥ë ¥ê³¼ í†µê³„ ì§€ì‹ ì¤‘ì‹¬"},
        "ì˜ì—…ì§": {"type": "ì¸ì„±ë©´ì ‘", "description": "ì„¤ë“ë ¥ê³¼ ê³ ê° ì§€í–¥ì„± ì¤‘ì‹¬"},
        "ì¸ì‚¬ì§": {"type": "ì¸ì„±ë©´ì ‘", "description": "ì†Œí†µ ëŠ¥ë ¥ê³¼ ì¡°ì§ ì´í•´ë„ ì¤‘ì‹¬"},
        "ì¬ë¬´ì§": {"type": "ê¸°ìˆ ë©´ì ‘", "description": "ì „ë¬¸ ì§€ì‹ê³¼ ë¶„ì„ ëŠ¥ë ¥ ì¤‘ì‹¬"},
        "ì¼ë°˜ì§": {"type": "ì¢…í•©ë©´ì ‘", "description": "ì „ë°˜ì ì¸ ì—­ëŸ‰ê³¼ ì¡°ì§ ì í•©ì„± ì¤‘ì‹¬"}
    }
    
    recommendation = recommendations.get(detected_type, recommendations["ì¼ë°˜ì§"])
    
    # ê²½ë ¥ë³„ ë‚œì´ë„ ì¶”ì²œ
    if any(keyword in career_level.lower() for keyword in ["ì‹ ì…", "new", "junior", "ì¡¸ì—…"]):
        difficulty = "ì´ˆê¸‰"
        question_count = 12
    elif any(keyword in career_level.lower() for keyword in ["ì‹œë‹ˆì–´", "senior", "ë¦¬ë“œ", "íŒ€ì¥", "ë§¤ë‹ˆì €"]):
        difficulty = "ê³ ê¸‰"
        question_count = 18
    else:
        difficulty = "ì¤‘ê¸‰"
        question_count = 15
    
    return {
        "job_type": detected_type,
        "recommended_interview_type": recommendation["type"],
        "recommended_difficulty": difficulty,
        "recommended_question_count": question_count,
        "description": recommendation["description"],
        "status": "success",
        "message": f"ğŸ¯ {detected_type}ì— ìµœì í™”ëœ {recommendation['type']} ({difficulty}, {question_count}ê°œ)ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤!"
    }

@tool
def collect_additional_info(field_name: str, field_value: str) -> Dict[str, Any]:
    """ì¶”ê°€ ê°œì¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    logger.info(f"ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘: {field_name} = {field_value}")
    
    field_mapping = {
        "career_goal": "ì»¤ë¦¬ì–´ ëª©í‘œ",
        "priority_values": "ìš°ì„ ìˆœìœ„ ê°€ì¹˜",
        "work_style": "ì„ í˜¸ ì—…ë¬´ ìŠ¤íƒ€ì¼",
        "application_source": "ì§€ì› ê²½ë¡œ",
        "domain_experience": "í•´ë‹¹ ë„ë©”ì¸ ê²½í—˜"
    }
    
    field_display = field_mapping.get(field_name, field_name)
    
    return {
        "field_name": field_name,
        "field_value": field_value.strip(),
        "status": "success",
        "message": f"âœ… {field_display} ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!"
    }

@tool
def set_interview_preferences(interview_type: str, difficulty_level: str, question_count: int) -> Dict[str, Any]:
    """ìµœì¢… ë©´ì ‘ ì„¤ì •ì„ í™•ì •í•©ë‹ˆë‹¤."""
    logger.info(f"ë©´ì ‘ ì„¤ì • í™•ì •: {interview_type}, {difficulty_level}, {question_count}")
    
    # ì…ë ¥ê°’ ì •ê·œí™”
    interview_types = {
        "ê¸°ìˆ ": "ê¸°ìˆ ë©´ì ‘", "ê¸°ìˆ ë©´ì ‘": "ê¸°ìˆ ë©´ì ‘", "tech": "ê¸°ìˆ ë©´ì ‘",
        "ì¸ì„±": "ì¸ì„±ë©´ì ‘", "ì¸ì„±ë©´ì ‘": "ì¸ì„±ë©´ì ‘", "personality": "ì¸ì„±ë©´ì ‘",
        "ì„ì›": "ì„ì›ë©´ì ‘", "ì„ì›ë©´ì ‘": "ì„ì›ë©´ì ‘", "executive": "ì„ì›ë©´ì ‘",
        "ì¢…í•©": "ì¢…í•©ë©´ì ‘", "ì¢…í•©ë©´ì ‘": "ì¢…í•©ë©´ì ‘", "comprehensive": "ì¢…í•©ë©´ì ‘"
    }
    
    difficulties = {
        "ì´ˆê¸‰": "ì´ˆê¸‰", "ì‰¬ìš´": "ì´ˆê¸‰", "easy": "ì´ˆê¸‰", "ê¸°ì´ˆ": "ì´ˆê¸‰",
        "ì¤‘ê¸‰": "ì¤‘ê¸‰", "ë³´í†µ": "ì¤‘ê¸‰", "medium": "ì¤‘ê¸‰", "ì¼ë°˜": "ì¤‘ê¸‰",
        "ê³ ê¸‰": "ê³ ê¸‰", "ì–´ë ¤ìš´": "ê³ ê¸‰", "hard": "ê³ ê¸‰", "ë†’ì€": "ê³ ê¸‰"
    }
    
    normalized_type = interview_types.get(interview_type.lower(), "ì¢…í•©ë©´ì ‘")
    normalized_difficulty = difficulties.get(difficulty_level.lower(), "ì¤‘ê¸‰")
    
    # ì§ˆë¬¸ ê°œìˆ˜ ê²€ì¦
    if question_count < 5:
        question_count = 5
    elif question_count > 30:
        question_count = 30
    
    return {
        "interview_type": normalized_type,
        "difficulty_level": normalized_difficulty,
        "question_count": question_count,
        "status": "success",
        "message": f"âš™ï¸ ë©´ì ‘ ì„¤ì •ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤: {normalized_type} ({normalized_difficulty}, {question_count}ê°œ)"
    }

@tool
def generate_personalized_questions(state_json: str) -> Dict[str, Any]:
    """ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("ê°œì¸ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„± ì‹œì‘")
    
    try:
        state_data = json.loads(state_json)
        
        api_key = os.getenv("OPENAI_API_KEY")
        llm = ChatOpenAI(api_key=api_key, model="gpt-4o-mini", temperature=0.7, max_tokens=4000)
        
        # ê¸°ì¡´ personal_question_maker.pyì˜ ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt = f"""
ë‹¹ì‹ ì€ {state_data.get('company_name', 'íšŒì‚¬')}ì˜ ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ì§€ì›ìì˜ ìƒì„¸ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ë§¤ìš° ê°œì¸í™”ëœ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

[ì§€ì›ì ê¸°ë³¸ ì •ë³´]
- íšŒì‚¬: {state_data.get('company_name', '')}
- ì§ë¬´: {state_data.get('position', '')}
- ê²½ë ¥êµ¬ë¶„: {state_data.get('career_level', '')}

[ì§€ì›ì ìƒì„¸ í”„ë¡œí•„]
- í•™ë ¥: {state_data.get('education_level', '')}
- ì „ê³µ: {state_data.get('major', '')}
- í•™ì : {state_data.get('gpa', '')}
- ìê²©ì¦: {state_data.get('certificates', '')}
- ì–´í•™ëŠ¥ë ¥: {state_data.get('language_skills', '')}
- ê¸°ìˆ ìŠ¤íƒ: {state_data.get('tech_stack', '')}
- ì„±ê²©ìœ í˜•: {state_data.get('personality_type', '')}
- í”„ë¡œì íŠ¸ê·œëª¨: {state_data.get('project_scale', '')}
- ë¦¬ë”ì‹­ê²½í—˜: {state_data.get('leadership_experience', '')}
- í¬íŠ¸í´ë¦¬ì˜¤: {state_data.get('portfolio_links', '')}
- ë¸”ë¡œê·¸í™œë™: {state_data.get('blog_activity', '')}
- SNSí™œë™: {state_data.get('sns_activity', '')}
- ì˜¤í”ˆì†ŒìŠ¤ê¸°ì—¬: {state_data.get('open_source', '')}
- ìˆ˜ìƒê²½ë ¥: {state_data.get('awards', '')}
- ëŒ€íšŒì°¸ì—¬: {state_data.get('competitions', '')}
- ë°œí‘œì¶œê°„: {state_data.get('publications', '')}
- ì»¤ë¦¬ì–´ëª©í‘œ: {state_data.get('career_goal', '')}
- ì—…ë¬´ìŠ¤íƒ€ì¼: {state_data.get('work_style', '')}

[ë©´ì ‘ ì„¤ì •]
- ë©´ì ‘ìœ í˜•: {state_data.get('interview_type', 'ì¢…í•©ë©´ì ‘')}
- ë‚œì´ë„: {state_data.get('difficulty_level', 'ì¤‘ê¸‰')}
- ì§ˆë¬¸ê°œìˆ˜: {state_data.get('question_count', 15)}ê°œ

[íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´]
{state_data.get('company_website_info', 'ì •ë³´ ì—†ìŒ')}

ìœ„ ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ë§¤ìš° êµ¬ì²´ì ì´ê³  ê°œì¸í™”ëœ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

### ì§ˆë¬¸ ìƒì„± ì›ì¹™
1. **ê°œì¸í™”**: ì§€ì›ìì˜ êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ì •ë³´ë¥¼ ì§ˆë¬¸ì— í¬í•¨
2. **ìœ í˜• íŠ¹í™”**: {state_data.get('interview_type', 'ì¢…í•©ë©´ì ‘')}ì˜ í•µì‹¬ í‰ê°€ ìš”ì†Œì— ì§‘ì¤‘
3. **ë‚œì´ë„ ì¡°ì ˆ**: {state_data.get('difficulty_level', 'ì¤‘ê¸‰')} ìˆ˜ì¤€ì— ë§ëŠ” ì§ˆë¬¸ ë³µì¡ë„
4. **íšŒì‚¬ ë§ì¶¤**: íšŒì‚¬ ì •ë³´ë¥¼ í™œìš©í•œ ë§ì¶¤í˜• ì§ˆë¬¸

### ì§ˆë¬¸ í˜•ì‹
ê° ì§ˆë¬¸ë§ˆë‹¤ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨:

**ì§ˆë¬¸ [ë²ˆí˜¸]: [ì§ˆë¬¸ ë‚´ìš©]**
- *í‰ê°€ ì˜ë„: ë¬´ì—‡ì„ í‰ê°€í•˜ë ¤ëŠ” ì§ˆë¬¸ì¸ì§€*
- *ê°œì¸í™” í¬ì¸íŠ¸: ì–´ë–¤ ê°œì¸ ì •ë³´ë¥¼ í™œìš©í–ˆëŠ”ì§€*
- *ì˜ˆìƒ ë‹µë³€ ì‹œê°„: 3-5ë¶„*

---

ì£¼ì˜ì‚¬í•­:
- ë¹ˆ ì •ë³´("")ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ , ìˆëŠ” ì •ë³´ë§Œ í™œìš©
- ê° ì§ˆë¬¸ì— êµ¬ì²´ì ì¸ ê°œì¸ ì •ë³´ë¥¼ í¬í•¨ì‹œì¼œ ê°œì¸í™”ëœ ëŠë‚Œì´ ë‚˜ë„ë¡ êµ¬ì„±
- "ê·€í•˜ì˜ GitHubì—ì„œ í™•ì¸í•œ XX í”„ë¡œì íŠ¸ë¥¼ ë³´ë‹ˆ...", "ìš°ë¦¬ íšŒì‚¬ì˜ YY ê°€ì¹˜ê´€ì— ëŒ€í•´..." ë“±ì˜ ë°©ì‹ í™œìš©

ì´ {state_data.get('question_count', 15)}ê°œì˜ ë§¤ìš° ê°œì¸ì ì´ê³  ë©´ì ‘ ìœ í˜•ì— íŠ¹í™”ëœ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = llm.invoke([HumanMessage(content=prompt)])
        questions = response.content
        
        # ë©´ì ‘ ìœ í˜•ë³„ ë§ì¶¤ íŒ ì¶”ê°€
        interview_type = state_data.get('interview_type', 'ì¢…í•©ë©´ì ‘')
        position = state_data.get('position', '')
        
        # ê¸°ì¡´ personal_question_maker.pyì˜ ìƒì„¸í•œ íŒ ë¡œì§ ì‚¬ìš©
        tips = generate_interview_tips(interview_type, position)
        
        full_content = f"""# ğŸ¯ {state_data.get('company_name', 'íšŒì‚¬')} - {state_data.get('position', 'ì§ë¬´')} ê°œì¸ ë§ì¶¤í˜• {interview_type}

## ğŸ“‹ ê°œì¸ í”„ë¡œí•„ ìš”ì•½
- **í•™ë ¥**: {state_data.get('education_level', '')} ({state_data.get('major', '')})
- **ê²½ë ¥êµ¬ë¶„**: {state_data.get('career_level', '')}
- **í•µì‹¬ ì—­ëŸ‰**: {state_data.get('tech_stack', '')}
- **ì„±ê²© íŠ¹ì„±**: {state_data.get('personality_type', '')}
- **ì»¤ë¦¬ì–´ ëª©í‘œ**: {state_data.get('career_goal', '')}

## âš™ï¸ ë©´ì ‘ ì„¤ì •
- **ë©´ì ‘ ìœ í˜•**: {interview_type}
- **ë‚œì´ë„**: {state_data.get('difficulty_level', 'ì¤‘ê¸‰')}
- **ì§ˆë¬¸ ê°œìˆ˜**: {state_data.get('question_count', 15)}ê°œ

---

{questions}

---

{tips}

**ë‹¹ì‹ ë§Œì˜ ë…íŠ¹í•œ ìŠ¤í† ë¦¬ì™€ {interview_type}ì— íŠ¹í™”ëœ ì¤€ë¹„ë¡œ ë©´ì ‘ê´€ì„ ê°ë™ì‹œí‚¤ì„¸ìš”! ğŸŒŸ**
"""
        
        return {
            "questions": full_content,
            "status": "success",
            "message": "ğŸ¯ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!"
        }
        
    except Exception as e:
        logger.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {
            "questions": f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "status": "error",
            "message": f"âŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }

@tool
def save_questions_to_file(questions: str, company_name: str, position: str, interview_type: str) -> Dict[str, Any]:
    """ìƒì„±ëœ ì§ˆë¬¸ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    logger.info("íŒŒì¼ ì €ì¥ ì‹œì‘")
    
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{interview_type}_{company_name}_{position}_{timestamp}.txt"
        safe_filename = "".join(c for c in filename if c.isalnum() or c in "._-í•œê¸€").strip()
        
        temp_dir = Path("temp_downloads")
        temp_dir.mkdir(exist_ok=True)
        
        file_path = temp_dir / safe_filename
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(questions)
        
        return {
            "file_path": str(file_path),
            "status": "success",
            "message": f"ğŸ’¾ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {safe_filename}"
        }
        
    except Exception as e:
        logger.error(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return {
            "file_path": "",
            "status": "error",
            "message": f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }


# ============ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ============
def generate_interview_tips(interview_type: str, position: str) -> str:
    """ë©´ì ‘ ìœ í˜•ë³„ ë§ì¶¤ íŒ ìƒì„± (ê¸°ì¡´ personal_question_maker.pyì—ì„œ)"""
    
    tips = f"""## ğŸ’¡ {interview_type} ë§ì¶¤ ì¤€ë¹„ íŒ

### ğŸ¯ {interview_type} í•µì‹¬ í¬ì¸íŠ¸"""
    
    if interview_type == "ê¸°ìˆ ë©´ì ‘":
        tips += """
1. **ê¸°ìˆ  ê¸°ì´ˆ ì§€ì‹**: CS ì „ê³µ ì§€ì‹ê³¼ ì‹¤ë¬´ ê²½í—˜ì„ ì—°ê²°í•´ì„œ ì„¤ëª…
2. **ì½”ë”© ì—­ëŸ‰**: ì•Œê³ ë¦¬ì¦˜ê³¼ ìë£Œêµ¬ì¡°, ì‹¤ì œ êµ¬í˜„ ê²½í—˜ ì •ë¦¬
3. **ì‹œìŠ¤í…œ ì„¤ê³„**: í™•ì¥ì„±, ì„±ëŠ¥, ë³´ì•ˆì„ ê³ ë ¤í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„ ê²½í—˜
4. **ê¸°ìˆ  íŠ¸ë Œë“œ**: ìµœì‹  ê¸°ìˆ ì— ëŒ€í•œ ê´€ì‹¬ê³¼ í•™ìŠµ ì˜ì§€ ì–´í•„
5. **ë¬¸ì œ í•´ê²°**: ë³µì¡í•œ ê¸°ìˆ ì  ë¬¸ì œë¥¼ í•´ê²°í•œ êµ¬ì²´ì  ì‚¬ë¡€ ì¤€ë¹„"""
    
    elif interview_type == "ì¸ì„±ë©´ì ‘":
        tips += """
1. **ê°€ì¹˜ê´€ ì •ë¦½**: ê°œì¸ì˜ í•µì‹¬ ê°€ì¹˜ì™€ íšŒì‚¬ ë¬¸í™”ì˜ ì¼ì¹˜ì  ê°•ì¡°
2. **íŒ€ì›Œí¬ ê²½í—˜**: í˜‘ì—… ê³¼ì •ì—ì„œì˜ ê°ˆë“± í•´ê²°ê³¼ ì†Œí†µ ë°©ì‹ ì‚¬ë¡€
3. **ì„±ì¥ ë§ˆì¸ë“œ**: ì‹¤íŒ¨ ê²½í—˜ê³¼ ê·¸ë¥¼ í†µí•œ í•™ìŠµ, ì„±ì¥ ìŠ¤í† ë¦¬
4. **ì¡°ì§ ì ì‘ë ¥**: ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œì˜ ì ì‘ ê²½í—˜ê³¼ ìœ ì—°ì„±
5. **ì†Œí†µ ëŠ¥ë ¥**: ë‹¤ì–‘í•œ ì´í•´ê´€ê³„ìì™€ì˜ íš¨ê³¼ì  ì†Œí†µ ê²½í—˜"""
    
    elif interview_type == "ì„ì›ë©´ì ‘":
        tips += """
1. **ë¦¬ë”ì‹­ ì² í•™**: ê°œì¸ì˜ ë¦¬ë”ì‹­ ìŠ¤íƒ€ì¼ê³¼ íŒ€ ê´€ë¦¬ ê²½í—˜
2. **ì „ëµì  ì‚¬ê³ **: ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ë¬¸ì œ ì¸ì‹ê³¼ í•´ê²° ë°©ì•ˆ
3. **ì˜ì‚¬ê²°ì •**: ì–´ë ¤ìš´ ìƒí™©ì—ì„œì˜ íŒë‹¨ ê¸°ì¤€ê³¼ ì±…ì„ê°
4. **ì¡°ì§ ê¸°ì—¬**: íšŒì‚¬ ì„±ì¥ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì  ë°©ì•ˆ
5. **ì¥ê¸° ë¹„ì „**: ê°œì¸ê³¼ ì¡°ì§ì˜ ë¯¸ë˜ ë°œì „ ë°©í–¥ì— ëŒ€í•œ ìƒê°"""
    
    else:  # ì¢…í•©ë©´ì ‘
        tips += """
1. **ì¢…í•©ì  ì—­ëŸ‰**: ê¸°ìˆ , ì¸ì„±, ë¦¬ë”ì‹­ì˜ ê· í˜•ì¡íŒ ë°œì „ ê³¼ì •
2. **íšŒì‚¬ ì´í•´**: íšŒì‚¬ì˜ ë¹„ì „, ê°€ì¹˜, ë¬¸í™”ì— ëŒ€í•œ ê¹Šì€ ì´í•´
3. **ì„±ì¥ ìŠ¤í† ë¦¬**: ì§€ì†ì ì¸ í•™ìŠµê³¼ ë°œì „ì„ ë³´ì—¬ì£¼ëŠ” ì¼ê´€ëœ ìŠ¤í† ë¦¬
4. **ì ì‘ë ¥**: ë³€í™”í•˜ëŠ” í™˜ê²½ì—ì„œì˜ ìœ ì—°ì„±ê³¼ í˜ì‹  ë§ˆì¸ë“œ
5. **ê¸°ì—¬ ë°©ì•ˆ**: íšŒì‚¬ì™€ íŒ€ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ì°¨ë³„í™”ëœ ê°€ì¹˜ ì œì•ˆ"""
    
    tips += f"""

### ğŸŒŸ ê°œì¸ ë§ì¶¤ í¬ì¸íŠ¸
- **GitHub/í¬íŠ¸í´ë¦¬ì˜¤**: ì£¼ìš” í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²° ê³¼ì •
- **ë¸”ë¡œê·¸/ê¸°ìˆ  ê¸€**: ì‘ì„±í•œ ë‚´ìš©ì˜ ë°°ê²½ê³¼ ì¸ì‚¬ì´íŠ¸
- **ìˆ˜ìƒ/ì„±ê³¼**: ì„±ì·¨ ê³¼ì •ì—ì„œì˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ê³¼ íŒ€ì›Œí¬
- **ì˜¤í”ˆì†ŒìŠ¤**: ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ ê²½í—˜ê³¼ í˜‘ì—… ëŠ¥ë ¥
- **íšŒì‚¬ ë¬¸í™”**: ìˆ˜ì§‘ëœ íšŒì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë¬¸í™” ì í•©ì„±"""
    
    return tips


# ============ LangGraph ë…¸ë“œ ì •ì˜ ============
def conversation_router(state: InterviewGeneratorState) -> InterviewGeneratorState:
    """ëŒ€í™” ë¼ìš°í„° - í•œ ë²ˆì— í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì‹¤í–‰"""
    
    last_message = state["messages"][-1] if state["messages"] else None
    if not last_message or not hasattr(last_message, 'content'):
        return state
    
    user_input = last_message.content.lower()
    
    # í˜„ì¬ ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
    company_name = state.get("company_name", "")
    position = state.get("position", "")
    resume_analyzed = bool(state.get("resume_content", ""))
    interview_settings = bool(state.get("interview_type", ""))
    questions_generated = bool(state.get("generated_questions", ""))
    files_saved = bool(state.get("generated_files", []))
    
    # ì¶”ì²œëœ ì„¤ì •ì´ ìˆëŠ”ì§€ í™•ì¸
    has_recommendations = bool(state.get("recommended_interview_type", ""))
    
    api_key = os.getenv("OPENAI_API_KEY")
    tools = [
        collect_basic_info,
        process_resume_file,
        suggest_interview_settings,
        collect_additional_info,
        set_interview_preferences,
        generate_personalized_questions,
        save_questions_to_file
    ]
    
    llm_with_tools = ChatOpenAI(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.3
    ).bind_tools(tools)
    
    # ìƒí™©ë³„ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
    if not company_name or not position:
        next_action = "íšŒì‚¬ëª…ê³¼ ì§ë¬´ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. collect_basic_infoë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    elif not resume_analyzed:
        next_action = "ì´ë ¥ì„œ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë ¥ì„œ ì—…ë¡œë“œë¥¼ ìš”ì²­í•˜ì„¸ìš”."
    elif not has_recommendations:
        next_action = "ë©´ì ‘ ì„¤ì • ì¶”ì²œì´ í•„ìš”í•©ë‹ˆë‹¤. suggest_interview_settingsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    elif not interview_settings:
        next_action = "ì¶”ì²œëœ ì„¤ì •ì„ í™•ì •í•´ì•¼ í•©ë‹ˆë‹¤. set_interview_preferencesë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    elif not questions_generated:
        next_action = "ì§ˆë¬¸ ìƒì„±ì´ í•„ìš”í•©ë‹ˆë‹¤. generate_personalized_questionsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    elif not files_saved:
        next_action = "íŒŒì¼ ì €ì¥ì´ í•„ìš”í•©ë‹ˆë‹¤. save_questions_to_fileë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    else:
        next_action = "ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œ ë©”ì‹œì§€ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
    
    # ë‹¨ìˆœí™”ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€
    system_prompt = f"""
ë‹¹ì‹ ì€ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ë‹¨ê³„ë³„ë¡œ í•˜ë‚˜ì”© ì§„í–‰í•©ë‹ˆë‹¤.

í˜„ì¬ ìƒíƒœ:
- íšŒì‚¬/ì§ë¬´: {company_name} {position} {'âœ…' if company_name and position else 'âŒ'}
- ì´ë ¥ì„œ ë¶„ì„: {'âœ…' if resume_analyzed else 'âŒ'}
- ì¶”ì²œ ì™„ë£Œ: {'âœ…' if has_recommendations else 'âŒ'}
- ì„¤ì • í™•ì •: {'âœ…' if interview_settings else 'âŒ'}
- ì§ˆë¬¸ ìƒì„±: {'âœ…' if questions_generated else 'âŒ'}
- íŒŒì¼ ì €ì¥: {'âœ…' if files_saved else 'âŒ'}

ë‹¤ìŒ ì•¡ì…˜: {next_action}

ì‚¬ìš©ìê°€ "ì§ˆë¬¸ ë§Œë“¤ì–´ì¤˜", "ì§ˆë¬¸ ìƒì„±", "ìƒì„±í•´ì¤˜" ë“±ì˜ ìš”ì²­ì„ í•˜ë©´:
- ì„¤ì •ì´ í™•ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ â†’ set_interview_preferencesë¡œ ì¶”ì²œëœ ì„¤ì •ì„ ë¨¼ì € í™•ì •
- ì„¤ì •ì´ í™•ì •ë˜ì—ˆë‹¤ë©´ â†’ generate_personalized_questionsë¡œ ì§ˆë¬¸ ìƒì„±

ì¶”ì²œëœ ì„¤ì • ì •ë³´:
- ë©´ì ‘ ìœ í˜•: {state.get('recommended_interview_type', '')}
- ë‚œì´ë„: {state.get('recommended_difficulty', '')}  
- ì§ˆë¬¸ ê°œìˆ˜: {state.get('recommended_question_count', 15)}

**í•œ ë²ˆì— í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì‚¬ìš©í•˜ì„¸ìš”!**
"""
    
    messages = [SystemMessage(content=system_prompt)] + state["messages"]
    
    try:
        response = llm_with_tools.invoke(messages)
        return {
            **state,
            "messages": [response],
        }
    except Exception as e:
        logger.error(f"ëŒ€í™” ë¼ìš°í„° ì˜¤ë¥˜: {str(e)}")
        error_response = AIMessage(content=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return {
            **state,
            "messages": [error_response],
            "error_message": str(e)
        }

def tools_executor(state: InterviewGeneratorState) -> InterviewGeneratorState:
    """ë„êµ¬ ì‹¤í–‰ ë…¸ë“œ"""
    
    last_message = state["messages"][-1]
    if not hasattr(last_message, 'tool_calls') or not last_message.tool_calls:
        return state
    
    tools = [
        collect_basic_info,
        process_resume_file,
        suggest_interview_settings,
        collect_additional_info,
        set_interview_preferences,
        generate_personalized_questions,
        save_questions_to_file
    ]
    
    tool_node = ToolNode(tools)
    tool_messages = tool_node.invoke({"messages": [last_message]})
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    updated_state = state.copy()
    
    for message in tool_messages["messages"]:
        if hasattr(message, 'name') and hasattr(message, 'content'):
            tool_name = message.name
            
            try:
                content = json.loads(message.content) if message.content.startswith('{') else {"result": message.content}
            except:
                content = {"result": message.content}
            
            # ë„êµ¬ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸
            if tool_name == "collect_basic_info" and content.get("status") == "success":
                updated_state["company_name"] = content.get("company_name", "")
                updated_state["position"] = content.get("position", "")
                updated_state["website_url"] = content.get("website_url", "")
                updated_state["company_website_info"] = content.get("company_website_info", "")
                updated_state["collected_fields"] = updated_state.get("collected_fields", []) + ["basic_info"]
                
            elif tool_name == "process_resume_file" and content.get("status") == "success":
                # ì´ë ¥ì„œì—ì„œ ì¶”ì¶œí•œ ëª¨ë“  ì •ë³´ ì—…ë°ì´íŠ¸
                resume_fields = [
                    "career_level", "education_level", "major", "gpa", "certificates",
                    "language_skills", "tech_stack", "personality_type", "project_scale",
                    "leadership_experience", "portfolio_links", "blog_activity",
                    "sns_activity", "open_source", "awards", "competitions", "publications"
                ]
                
                for field in resume_fields:
                    if field in content:
                        updated_state[field] = content[field]
                
                updated_state["resume_content"] = content.get("resume_content", "")
                updated_state["collected_fields"] = updated_state.get("collected_fields", []) + ["resume_analysis"]
                
            elif tool_name == "suggest_interview_settings" and content.get("status") == "success":
                # ì¶”ì²œ ì„¤ì •ì„ ì„ì‹œ ì €ì¥ (ì‚¬ìš©ì í™•ì¸ í›„ í™•ì •)
                updated_state["recommended_interview_type"] = content.get("recommended_interview_type", "")
                updated_state["recommended_difficulty"] = content.get("recommended_difficulty", "")
                updated_state["recommended_question_count"] = content.get("recommended_question_count", 15)
                updated_state["collected_fields"] = updated_state.get("collected_fields", []) + ["settings_recommended"]
                
            elif tool_name == "collect_additional_info" and content.get("status") == "success":
                field_name = content.get("field_name", "")
                field_value = content.get("field_value", "")
                if field_name and field_value:
                    updated_state[field_name] = field_value
                
            elif tool_name == "set_interview_preferences" and content.get("status") == "success":
                updated_state["interview_type"] = content.get("interview_type", "")
                updated_state["difficulty_level"] = content.get("difficulty_level", "")
                updated_state["question_count"] = content.get("question_count", 15)
                updated_state["collected_fields"] = updated_state.get("collected_fields", []) + ["interview_settings"]
                
            elif tool_name == "generate_personalized_questions" and content.get("status") == "success":
                updated_state["generated_questions"] = content.get("questions", "")
                updated_state["collected_fields"] = updated_state.get("collected_fields", []) + ["questions_generated"]
                
            elif tool_name == "save_questions_to_file" and content.get("status") == "success":
                file_path = content.get("file_path", "")
                if file_path:
                    updated_state["generated_files"] = updated_state.get("generated_files", []) + [file_path]
                    updated_state["is_complete"] = True
    
    updated_state["messages"] = tool_messages["messages"]
    return updated_state

def should_continue(state: InterviewGeneratorState) -> str:
    """ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    
    if not state.get("messages"):
        return END
    
    last_message = state["messages"][-1]
    
    # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    
    # ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ
    if state.get("is_complete", False):
        return END
    
    # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
    if state.get("error_message"):
        return END
    
    # ê¸°ë³¸ì ìœ¼ë¡œëŠ” ì¢…ë£Œ (ë¬´í•œë£¨í”„ ë°©ì§€)
    return END


# ============ LangGraph ì›Œí¬í”Œë¡œìš° ============
def create_enhanced_workflow() -> StateGraph:
    """ê°•í™”ëœ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„± - ë¬´í•œë£¨í”„ ë°©ì§€"""
    
    workflow = StateGraph(InterviewGeneratorState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("conversation", conversation_router)
    workflow.add_node("tools", tools_executor)
    
    # ì—£ì§€ ì¶”ê°€ - ë¬´í•œë£¨í”„ ì™„ì „ ì°¨ë‹¨
    workflow.add_edge(START, "conversation")
    workflow.add_conditional_edges(
        "conversation",
        should_continue,
        {"tools": "tools", END: END}
    )
    # tools ì‹¤í–‰ í›„ ë°”ë¡œ ì¢…ë£Œ - ëŒ€í™” ë…¸ë“œë¡œ ëŒì•„ê°€ì§€ ì•ŠìŒ
    workflow.add_edge("tools", END)
    
    return workflow.compile(debug=False)


# ============ ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤ ============
class EnhancedLangGraphInterviewGenerator:
    """ê°•í™”ëœ LangGraph ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        self.workflow = create_enhanced_workflow()
        self.reset_conversation()
    
    def reset_conversation(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        self.state = {
            "messages": [],
            "company_name": "",
            "position": "",
            "career_level": "",
            "website_url": "",
            "education_level": "",
            "major": "",
            "gpa": "",
            "certificates": "",
            "language_skills": "",
            "tech_stack": "",
            "personality_type": "",
            "project_scale": "",
            "leadership_experience": "",
            "domain_experience": "",
            "portfolio_links": "",
            "blog_activity": "",
            "sns_activity": "",
            "open_source": "",
            "awards": "",
            "competitions": "",
            "publications": "",
            "application_source": "",
            "priority_values": "",
            "career_goal": "",
            "work_style": "",
            "interview_type": "",
            "difficulty_level": "",
            "question_count": 15,
            "resume_content": "",
            "company_website_info": "",
            "generated_questions": "",
            "generated_files": [],
            "current_step": "start",
            "collected_fields": [],
            "is_complete": False,
            "error_message": ""
        }
    
    def process_file_upload(self, file_path: str) -> Dict[str, Any]:
        """íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ - ìƒíƒœ ì—…ë°ì´íŠ¸ í¬í•¨"""
        if not file_path:
            return {"status": "error", "message": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # process_resume_file ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œ
            result = process_resume_file.invoke({"file_path": file_path})
            
            if isinstance(result, dict) and result.get("status") == "success":
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                resume_fields = [
                    "career_level", "education_level", "major", "gpa", "certificates",
                    "language_skills", "tech_stack", "personality_type", "project_scale",
                    "leadership_experience", "portfolio_links", "blog_activity",
                    "sns_activity", "open_source", "awards", "competitions", "publications"
                ]
                
                for field in resume_fields:
                    if field in result and result[field]:
                        self.state[field] = result[field]
                
                self.state["resume_content"] = result.get("resume_content", "")
                self.state["collected_fields"] = self.state.get("collected_fields", []) + ["resume_analysis"]
                
                # ì¶”ì¶œëœ ì •ë³´ë¥¼ í¬í•¨í•œ ìƒì„¸ ë©”ì‹œì§€ ìƒì„±
                extracted_info = []
                if result.get("career_level"): extracted_info.append(f"ê²½ë ¥: {result['career_level']}")
                if result.get("education_level"): extracted_info.append(f"í•™ë ¥: {result['education_level']}")
                if result.get("major"): extracted_info.append(f"ì „ê³µ: {result['major']}")
                if result.get("tech_stack"): extracted_info.append(f"ê¸°ìˆ ìŠ¤íƒ: {result['tech_stack']}")
                if result.get("project_scale"): extracted_info.append(f"í”„ë¡œì íŠ¸ ê·œëª¨: {result['project_scale']}")
                
                info_text = "\n".join([f"- {info}" for info in extracted_info])
                
                return {
                    "status": "success",
                    "message": f"ğŸ“‹ ì´ë ¥ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n**ì¶”ì¶œëœ ì •ë³´:**\n{info_text}",
                    "extracted_info": extracted_info
                }
            else:
                return {
                    "status": "error", 
                    "message": result.get("message", "âŒ ì´ë ¥ì„œ ì²˜ë¦¬ ì‹¤íŒ¨")
                }
                
        except Exception as e:
            logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {
                "status": "error",
                "message": f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"
            }
    
    def chat(self, message: str, history: List, files=None) -> tuple:
        """ë©”ì¸ ì±„íŒ… ì²˜ë¦¬"""
        try:
            logger.info(f"ì±„íŒ… ì²˜ë¦¬: {message}")
            
            # ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœë©´ ì™„ë£Œ ë©”ì‹œì§€ë§Œ ë°˜í™˜
            if self.state.get("is_complete", False):
                complete_msg = "ğŸ‰ ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ìœ„ì˜ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•´ì„œ ë©´ì ‘ ì§ˆë¬¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
                history.append([message, complete_msg])
                return history, ""
            
            # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
            file_processing_result = None
            if files:
                file_path = files.name if hasattr(files, 'name') else str(files)
                file_processing_result = self.process_file_upload(file_path)
                
                if file_processing_result["status"] == "success":
                    # íŒŒì¼ ì²˜ë¦¬ ì„±ê³µ ì‹œ ë¶„ì„ëœ ì •ë³´ë¥¼ ë©”ì‹œì§€ì— í¬í•¨
                    message += f"\n\n[ì´ë ¥ì„œ ë¶„ì„ ì™„ë£Œ]\n{file_processing_result['message']}"
                else:
                    # íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
                    message += f"\n\n[íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨]\n{file_processing_result['message']}"
            
            # ì´ˆê¸°í™” ëª…ë ¹ì–´ ì²´í¬
            if any(cmd in message.lower() for cmd in ["ì²˜ìŒë¶€í„°", "ì´ˆê¸°í™”", "ë¦¬ì…‹", "ë‹¤ì‹œ"]):
                self.reset_conversation()
                welcome_msg = """ì•ˆë…•í•˜ì„¸ìš”! ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤ ğŸ¯

ì €ëŠ” ë‹¹ì‹ ì˜ ìƒì„¸í•œ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ì „íˆ ê°œì¸í™”ëœ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.

**ğŸš€ ì¤€ë¹„ëœ ê¸°ëŠ¥ë“¤:**
- ğŸ“‹ 20+ ê°œì¸ í”„ë¡œí•„ í•„ë“œ ìë™ ë¶„ì„
- ğŸŒ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘
- ğŸ¯ ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ìë™ ì¶”ì²œ  
- âš™ï¸ ë‚œì´ë„ ë° ì§ˆë¬¸ ê°œìˆ˜ ë§ì¶¤ ì„¤ì •
- ğŸ’¡ ë©´ì ‘ ìœ í˜•ë³„ ì¤€ë¹„ íŒ ì œê³µ

ì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”? íšŒì‚¬ëª…ê³¼ ì§€ì› ì§ë¬´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"""
                history.append([message, welcome_msg])
                return history, ""
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„± - í˜„ì¬ ìƒíƒœ ì •ë³´ í¬í•¨
            user_content = message
            if file_processing_result and file_processing_result["status"] == "success":
                # ì¶”ì¶œëœ ì •ë³´ê°€ ìˆìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                extracted = file_processing_result.get("extracted_info", [])
                if extracted:
                    user_content += f"\n\n[í˜„ì¬ íŒŒì•…ëœ ì •ë³´: {', '.join(extracted)}]"
            
            human_message = HumanMessage(content=user_content)
            self.state["messages"] = [human_message]
            
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ - recursion_limit ì¦ê°€
            config = {"recursion_limit": 5}  # ì¤„ì—¬ì„œ ë¹ ë¥¸ ì¢…ë£Œ
            result = self.workflow.invoke(self.state, config=config)
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.state.update(result)
            
            # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ì¶œ
            response_content = "ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."
            if result.get("messages"):
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content') and last_message.content:
                    response_content = last_message.content
                    
                    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì¶”ê°€
                    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                        tool_info = self._format_tool_results(result.get("messages", []))
                        if tool_info:
                            response_content += f"\n\n{tool_info}"
            
            # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            history.append([message, response_content])
            
            return history, ""
            
        except Exception as e:
            logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            history.append([message, error_msg])
            return history, ""
    
    def _format_tool_results(self, messages: List) -> str:
        """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í¬ë§·íŒ…"""
        results = []
        
        for message in messages:
            if hasattr(message, 'name') and hasattr(message, 'content'):
                try:
                    content = json.loads(message.content) if message.content.startswith('{') else {}
                    if content.get("message"):
                        results.append(content["message"])
                except:
                    pass
        
        return "\n".join(results) if results else ""
    
    def get_current_status(self) -> Dict:
        """í˜„ì¬ ìƒíƒœ ì •ë³´"""
        collected = self.state.get("collected_fields", [])
        progress = len(collected) / 6 * 100  # ì´ 6ë‹¨ê³„
        
        return {
            "progress": f"{progress:.0f}%",
            "company_name": self.state.get("company_name", ""),
            "position": self.state.get("position", ""),
            "resume_analyzed": bool(self.state.get("resume_content")),
            "interview_settings": bool(self.state.get("interview_type")),
            "questions_generated": bool(self.state.get("generated_questions")),
            "is_complete": self.state.get("is_complete", False),
            "collected_fields": collected
        }
    
    def get_download_files(self) -> List[str]:
        """ë‹¤ìš´ë¡œë“œ íŒŒì¼ ëª©ë¡"""
        return self.state.get("generated_files", [])
    
    def create_interface(self):
        """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
        
        with gr.Blocks(
            title="LangGraph ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°",
            theme=gr.themes.Soft(),
            css="""
            .status-panel { 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 20px;
                border-radius: 10px;
                margin: 10px 0;
            }
            .chat-container { 
                max-height: 600px;
                overflow-y: auto;
                border: 1px solid #e1e5e9;
                border-radius: 8px;
            }
            .feature-box {
                background: #f8f9fa;
                padding: 15px;
                border-radius: 8px;
                border-left: 4px solid #667eea;
                margin: 10px 0;
            }
            """
        ) as demo:
            
            gr.Markdown("""
            # ğŸ¯ LangGraph ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°
            
            **personal_question_maker.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ëŒ€í™”í˜•ìœ¼ë¡œ êµ¬í˜„**
            
            âœ¨ **Enhanced Features:**
            - ğŸ¤– **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ë‹¨ê³„ë³„ ì •ë³´ ìˆ˜ì§‘ê³¼ ë§ì¶¤ ì•ˆë‚´
            - ğŸ“‹ **ìƒì„¸ í”„ë¡œí•„ ë¶„ì„**: 20+ ê°œì¸ ì •ë³´ í•„ë“œ ìë™ ì¶”ì¶œ
            - ğŸ¯ **ìŠ¤ë§ˆíŠ¸ ì¶”ì²œ**: ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ë° ë‚œì´ë„ ìë™ ì¶”ì²œ
            - ğŸŒ **íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘**: ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ìœ¼ë¡œ ë§ì¶¤ ì§ˆë¬¸ ìƒì„±
            - ğŸ”„ **ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°**: ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶”ì 
            - ğŸ’¡ **ë©´ì ‘ íŒ ì œê³µ**: ìœ í˜•ë³„/ì§ë¬´ë³„ ìƒì„¸ ì¤€ë¹„ ê°€ì´ë“œ
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    # ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
                    chatbot = gr.Chatbot(
                        value=[[None, """ì•ˆë…•í•˜ì„¸ìš”! ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤ ğŸ¯

ì €ëŠ” ë‹¹ì‹ ì˜ ìƒì„¸í•œ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ì „íˆ ê°œì¸í™”ëœ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.

**ğŸš€ ì¤€ë¹„ëœ ê¸°ëŠ¥ë“¤:**
- ğŸ“‹ 20+ ê°œì¸ í”„ë¡œí•„ í•„ë“œ ìë™ ë¶„ì„
- ğŸŒ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘
- ğŸ¯ ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ìë™ ì¶”ì²œ  
- âš™ï¸ ë‚œì´ë„ ë° ì§ˆë¬¸ ê°œìˆ˜ ë§ì¶¤ ì„¤ì •
- ğŸ’¡ ë©´ì ‘ ìœ í˜•ë³„ ì¤€ë¹„ íŒ ì œê³µ

ì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”? íšŒì‚¬ëª…ê³¼ ì§€ì› ì§ë¬´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"""]],
                        label="ğŸ¯ ë©´ì ‘ ì¤€ë¹„ ëŒ€í™”",
                        height=500,
                        elem_classes=["chat-container"]
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            label="ğŸ’¬ ë©”ì‹œì§€",
                            placeholder="ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”... (ì˜ˆ: ì¹´ì¹´ì˜¤ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œ ì§€ì›í•©ë‹ˆë‹¤)",
                            scale=3
                        )
                        file_upload = gr.File(
                            label="ğŸ“ ì´ë ¥ì„œ ì—…ë¡œë“œ",
                            file_types=[".pdf", ".docx", ".txt"],
                            scale=1
                        )
                    
                    with gr.Row():
                        send_btn = gr.Button("ğŸ“¤ ì „ì†¡", variant="primary", scale=2)
                        clear_btn = gr.Button("ğŸ”„ ìƒˆë¡œ ì‹œì‘", scale=1)
                
                with gr.Column(scale=1):
                    # ì§„í–‰ ìƒí™© íŒ¨ë„
                    gr.Markdown("### ğŸ“Š ì§„í–‰ ìƒí™©", elem_classes=["status-panel"])
                    
                    status_display = gr.JSON(
                        label="í˜„ì¬ ìƒíƒœ",
                        value={
                            "progress": "0%",
                            "company_name": "ë¯¸ì…ë ¥",
                            "position": "ë¯¸ì…ë ¥", 
                            "resume_analyzed": False,
                            "interview_settings": False,
                            "questions_generated": False,
                            "is_complete": False
                        }
                    )
                    
                    # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜
                    gr.Markdown("### ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                    download_btn = gr.DownloadButton(
                        "ğŸ“„ ë©´ì ‘ ì§ˆë¬¸ ë‹¤ìš´ë¡œë“œ",
                        visible=False,
                        variant="secondary"
                    )
                    
                    download_status = gr.Markdown(
                        "**ì§„í–‰ ë‹¨ê³„:**\n1. âœ… ê¸°ë³¸ ì •ë³´ ì…ë ¥\n2. â³ ì´ë ¥ì„œ ë¶„ì„\n3. â³ ì„¤ì • í™•ì •\n4. â³ ì§ˆë¬¸ ìƒì„±\n5. â³ íŒŒì¼ ì €ì¥",
                        elem_classes=["feature-box"]
                    )
            
            # ê¸°ëŠ¥ ì„¤ëª…
            with gr.Accordion("ğŸ”§ ìƒì„¸ ê¸°ëŠ¥ ì•ˆë‚´", open=False):
                gr.Markdown("""
                ### ğŸ¯ ìˆ˜ì§‘ë˜ëŠ” ê°œì¸ í”„ë¡œí•„ ì •ë³´
                
                **ğŸ“š í•™ë ¥ ì •ë³´**
                - ìµœì¢… í•™ë ¥, ì „ê³µ, í•™ì 
                
                **ğŸ† ì—­ëŸ‰ ì •ë³´**  
                - ìê²©ì¦, ì–´í•™ ëŠ¥ë ¥, ê¸°ìˆ  ìŠ¤íƒ, ì„±ê²© ìœ í˜•
                
                **ğŸ’¼ ê²½í—˜ ì •ë³´**
                - í”„ë¡œì íŠ¸ ê·œëª¨, ë¦¬ë”ì‹­ ê²½í—˜, ë„ë©”ì¸ ê²½í—˜
                
                **ğŸŒ ì˜¨ë¼ì¸ í™œë™**
                - í¬íŠ¸í´ë¦¬ì˜¤ ë§í¬, ë¸”ë¡œê·¸ í™œë™, SNS í™œë™, ì˜¤í”ˆì†ŒìŠ¤ ê¸°ì—¬
                
                **ğŸ… ì„±ê³¼ ê¸°ë¡**
                - ìˆ˜ìƒ ê²½ë ¥, ëŒ€íšŒ ì°¸ì—¬, ë°œí‘œ/ì¶œê°„ ê²½ë ¥
                
                **ğŸ¯ ì§€ì› ë™ê¸°**
                - ì§€ì› ê²½ë¡œ, ìš°ì„ ìˆœìœ„ ê°€ì¹˜, ì»¤ë¦¬ì–´ ëª©í‘œ, ì—…ë¬´ ìŠ¤íƒ€ì¼
                
                ### ğŸ¤– ìŠ¤ë§ˆíŠ¸ ì¶”ì²œ ì‹œìŠ¤í…œ
                
                **ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ìë™ ì¶”ì²œ:**
                - ğŸ–¥ï¸ **ê°œë°œì§** â†’ ê¸°ìˆ ë©´ì ‘ (ê¸°ìˆ  ì—­ëŸ‰ ì¤‘ì‹¬)
                - ğŸ“‹ **ê¸°íšì§** â†’ ì¢…í•©ë©´ì ‘ (ë…¼ë¦¬ì  ì‚¬ê³  ì¤‘ì‹¬)
                - ğŸ“ˆ **ë§ˆì¼€íŒ…ì§** â†’ ì¸ì„±ë©´ì ‘ (ì°½ì˜ì„± ì¤‘ì‹¬)
                - ğŸ¨ **ë””ìì¸ì§** â†’ ê¸°ìˆ ë©´ì ‘ (í¬íŠ¸í´ë¦¬ì˜¤ ì¤‘ì‹¬)
                - ğŸ“Š **ë°ì´í„°ì§** â†’ ê¸°ìˆ ë©´ì ‘ (ë¶„ì„ ëŠ¥ë ¥ ì¤‘ì‹¬)
                
                **ê²½ë ¥ë³„ ë‚œì´ë„ ìë™ ì¡°ì •:**
                - ğŸ‘¨â€ğŸ“ **ì‹ ì…** â†’ ì´ˆê¸‰ ë‚œì´ë„, 10-12ê°œ ì§ˆë¬¸
                - ğŸ‘©â€ğŸ’¼ **ê²½ë ¥** â†’ ì¤‘ê¸‰ ë‚œì´ë„, 15-18ê°œ ì§ˆë¬¸  
                - ğŸ‘¨â€ğŸ’¼ **ì‹œë‹ˆì–´** â†’ ê³ ê¸‰ ë‚œì´ë„, 18-22ê°œ ì§ˆë¬¸
                
                ### ğŸ“‹ ì§ˆë¬¸ ìƒì„± íŠ¹ì§•
                
                - **ğŸ¯ ì™„ì „ ê°œì¸í™”**: ì´ë ¥ì„œ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
                - **ğŸ¢ íšŒì‚¬ ë§ì¶¤**: ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìˆ˜ì§‘í•œ íšŒì‚¬ ë¬¸í™” ë°˜ì˜
                - **âš™ï¸ ìœ í˜•ë³„ íŠ¹í™”**: ë©´ì ‘ ìœ í˜•ì— ë”°ë¥¸ í‰ê°€ ìš”ì†Œ ì§‘ì¤‘
                - **ğŸ“Š ë‚œì´ë„ ì¡°ì ˆ**: ê²½ë ¥ê³¼ ì§ë¬´ì— ë§ëŠ” ì§ˆë¬¸ ë³µì¡ë„
                - **ğŸ’¡ ì¤€ë¹„ íŒ**: ê° ì§ˆë¬¸ë³„ í‰ê°€ ì˜ë„ì™€ ë‹µë³€ ê°€ì´ë“œ
                
                ### ğŸŒŸ personal_question_maker.py ëŒ€ë¹„ ê°œì„ ì 
                
                1. **ğŸ¤– ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ë³µì¡í•œ UI ëŒ€ì‹  í¸ë¦¬í•œ ì±„íŒ…
                2. **ğŸ”„ ì§€ëŠ¥ì  ì›Œí¬í”Œë¡œìš°**: ë‹¨ê³„ë³„ ìë™ ì§„í–‰ ë° ì•ˆë‚´
                3. **ğŸ“Š ì‹¤ì‹œê°„ ìƒíƒœ í™•ì¸**: ì§„í–‰ ìƒí™©ê³¼ ìˆ˜ì§‘ëœ ì •ë³´ ì‹œê°í™”
                4. **ğŸ› ï¸ ìŠ¤ë§ˆíŠ¸ ë„êµ¬ ì„ íƒ**: ìƒí™©ì— ë§ëŠ” ë„êµ¬ ìë™ ì‹¤í–‰
                5. **ğŸ¯ ê°œì¸í™” ê°•í™”**: ë” í’ë¶€í•œ í”„ë¡œí•„ ë°ì´í„° í™œìš©
                """)
            
            # ì‚¬ìš© ì˜ˆì‹œ
            with gr.Accordion("ğŸ’¬ ëŒ€í™” ì˜ˆì‹œ", open=False):
                gr.Markdown("""
                ### ğŸ—£ï¸ ì‹¤ì œ ëŒ€í™” íë¦„ ì˜ˆì‹œ
                
                **ğŸ‘¤ ì‚¬ìš©ì**: "ì•ˆë…•í•˜ì„¸ìš”! ë„¤ì´ë²„ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œ ì§€ì›í•˜ëŠ”ë° ê¸°ìˆ ë©´ì ‘ ì¤€ë¹„í•˜ê³  ì‹¶ì–´ìš”"
                
                **ğŸ¤– AI**: "ë„¤ì´ë²„ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì ì§€ì›ì„ ì¶•í•˜ë“œë¦½ë‹ˆë‹¤! ğŸ‰ ê¸°ìˆ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
                
                ë„¤ì´ë²„ ì›¹ì‚¬ì´íŠ¸ë„ í™•ì¸í•´ì„œ íšŒì‚¬ ì •ë³´ë¥¼ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤. ì´ë ¥ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì‹œê±°ë‚˜, ê°„ë‹¨í•œ ê²½ë ¥ì‚¬í•­ì„ ë¨¼ì € ì•Œë ¤ì£¼ì„¸ìš”."
                
                **ğŸ‘¤ ì‚¬ìš©ì**: [ì´ë ¥ì„œ PDF ì—…ë¡œë“œ]
                
                **ğŸ¤– AI**: "ğŸ“‹ ì´ë ¥ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
                
                **ì¶”ì¶œëœ ì •ë³´:**
                - ê²½ë ¥: React 3ë…„ ê²½í—˜ ê²½ë ¥ì§
                - ê¸°ìˆ ìŠ¤íƒ: React, TypeScript, Next.js, AWS
                - í”„ë¡œì íŠ¸: ëŒ€ê·œëª¨ íŒ€ í”„ë¡œì íŠ¸ ê²½í—˜
                - í¬íŠ¸í´ë¦¬ì˜¤: GitHub í™œë°œí•œ í™œë™
                
                ê°œë°œì§ì— ìµœì í™”ëœ **ê¸°ìˆ ë©´ì ‘ (ì¤‘ê¸‰, 15ê°œ)** ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ì–´ìš”?"
                
                **ğŸ‘¤ ì‚¬ìš©ì**: "ë„¤, ì¢‹ìŠµë‹ˆë‹¤!"
                
                **ğŸ¤– AI**: "âš™ï¸ ë©´ì ‘ ì„¤ì •ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤!
                
                ì¶”ê°€ë¡œ ì»¤ë¦¬ì–´ ëª©í‘œë‚˜ ì„ í˜¸í•˜ëŠ” ì—…ë¬´ ìŠ¤íƒ€ì¼ì„ ì•Œë ¤ì£¼ì‹œë©´ ë” ê°œì¸í™”ëœ ì§ˆë¬¸ì„ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”. ë°”ë¡œ ì§ˆë¬¸ ìƒì„±ì„ ì›í•˜ì‹œë©´ 'ì§ˆë¬¸ ìƒì„±í•´ì£¼ì„¸ìš”'ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”."
                
                **ğŸ‘¤ ì‚¬ìš©ì**: "ì‚¬ìš©ì ê²½í—˜ì„ ì¤‘ì‹œí•˜ê³  íŒ€ê³¼ í˜‘ì—…ì„ ì¢‹ì•„í•´ìš”. 5ë…„ í›„ì—” í”„ë¡ íŠ¸ì—”ë“œ ë¦¬ë“œê°€ ë˜ê³  ì‹¶ìŠµë‹ˆë‹¤."
                
                **ğŸ¤– AI**: "âœ… ì¶”ê°€ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!
                
                ğŸ¯ **ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!**
                
                **ì§ˆë¬¸ ë¯¸ë¦¬ë³´ê¸°:**
                1. ê·€í•˜ì˜ GitHubì„ ë³´ë‹ˆ TypeScript ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì íŠ¸ê°€ ì¸ìƒì ì…ë‹ˆë‹¤. ê¸°ì¡´ JavaScript ì½”ë“œë² ì´ìŠ¤ë¥¼ TypeScriptë¡œ ì „í™˜í•˜ë©´ì„œ ê²ªì€ ì£¼ìš” ë„ì „ê³¼ì œì™€ í•´ê²° ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                
                2. ë„¤ì´ë²„ì˜ ì‚¬ìš©ì ì¤‘ì‹¬ ì„œë¹„ìŠ¤ ì² í•™ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë©°, í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìë¡œì„œ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒì„ ìœ„í•´ ì–´ë–¤ ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­ì´ ì¤‘ìš”í•˜ë‹¤ê³  ë³´ì‹œë‚˜ìš”?
                
                (ì´ 15ê°œ ì§ˆë¬¸ê³¼ ìƒì„¸í•œ ì¤€ë¹„ íŒì´ í¬í•¨ëœ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”!)
                
                ğŸ’¾ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ê¸°ìˆ ë©´ì ‘_ë„¤ì´ë²„_í”„ë¡ íŠ¸ì—”ë“œê°œë°œì_20241208_143022.txt"
                
                ### ğŸ¯ í•µì‹¬ íŠ¹ì§•
                
                1. **ğŸ”„ ë‹¨ê³„ë³„ ìë™ ì§„í–‰**: ì‚¬ìš©ìê°€ ë³µì¡í•œ ì„¤ì •ì„ ëª°ë¼ë„ AIê°€ ì•Œì•„ì„œ ì§„í–‰
                2. **ğŸ“‹ ì§€ëŠ¥ì  ì •ë³´ ì¶”ì¶œ**: ì´ë ¥ì„œì—ì„œ 20+ í•„ë“œ ìë™ ë¶„ì„
                3. **ğŸ¯ ìŠ¤ë§ˆíŠ¸ ì¶”ì²œ**: ì§ë¬´ì™€ ê²½ë ¥ì— ë§ëŠ” ìµœì  ì„¤ì • ì œì•ˆ
                4. **ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”**: ë§ˆì¹˜ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì™€ ëŒ€í™”í•˜ëŠ” ëŠë‚Œ
                5. **ğŸŒ íšŒì‚¬ ë§ì¶¤**: ì‹¤ì œ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ë°˜ì˜
                6. **ğŸ’¡ ìƒì„¸í•œ ê°€ì´ë“œ**: ê° ì§ˆë¬¸ë³„ í‰ê°€ ì˜ë„ì™€ ì¤€ë¹„ íŒ
                """)
            
            # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
            def send_message(message, history, files):
                new_history, _ = self.chat(message, history, files)
                status = self.get_current_status()
                
                # ë‹¤ìš´ë¡œë“œ íŒŒì¼ í™•ì¸
                download_files = self.get_download_files()
                download_file = download_files[0] if download_files else None
                
                # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
                steps = [
                    "1. âœ… ê¸°ë³¸ ì •ë³´ ì…ë ¥" if status["company_name"] else "1. â³ ê¸°ë³¸ ì •ë³´ ì…ë ¥",
                    "2. âœ… ì´ë ¥ì„œ ë¶„ì„" if status["resume_analyzed"] else "2. â³ ì´ë ¥ì„œ ë¶„ì„", 
                    "3. âœ… ì„¤ì • í™•ì •" if status["interview_settings"] else "3. â³ ì„¤ì • í™•ì •",
                    "4. âœ… ì§ˆë¬¸ ìƒì„±" if status["questions_generated"] else "4. â³ ì§ˆë¬¸ ìƒì„±",
                    "5. âœ… ì™„ë£Œ!" if status["is_complete"] else "5. â³ íŒŒì¼ ì €ì¥"
                ]
                
                progress_msg = f"**ì§„í–‰ë¥ : {status['progress']}**\n\n" + "\n".join(steps)
                
                if status["is_complete"]:
                    progress_msg += "\n\nğŸ‰ **ëª¨ë“  ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**\nğŸ“¥ ìœ„ ë²„íŠ¼ìœ¼ë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
                
                return (
                    new_history, "", status,
                    gr.update(value=download_file, visible=bool(download_file)),
                    progress_msg
                )
            
            def clear_chat():
                self.reset_conversation()
                return (
                    [[None, """ì•ˆë…•í•˜ì„¸ìš”! ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤ ğŸ¯

ì €ëŠ” ë‹¹ì‹ ì˜ ìƒì„¸í•œ í”„ë¡œí•„ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ì „íˆ ê°œì¸í™”ëœ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ë“œë¦½ë‹ˆë‹¤.

**ğŸš€ ì¤€ë¹„ëœ ê¸°ëŠ¥ë“¤:**
- ğŸ“‹ 20+ ê°œì¸ í”„ë¡œí•„ í•„ë“œ ìë™ ë¶„ì„
- ğŸŒ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ì •ë³´ ìˆ˜ì§‘
- ğŸ¯ ì§ë¬´ë³„ ë©´ì ‘ ìœ í˜• ìë™ ì¶”ì²œ  
- âš™ï¸ ë‚œì´ë„ ë° ì§ˆë¬¸ ê°œìˆ˜ ë§ì¶¤ ì„¤ì •
- ğŸ’¡ ë©´ì ‘ ìœ í˜•ë³„ ì¤€ë¹„ íŒ ì œê³µ

ì–´ë–¤ íšŒì‚¬ì— ì§€ì›í•˜ì‹œë‚˜ìš”? íšŒì‚¬ëª…ê³¼ ì§€ì› ì§ë¬´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”!"""]],
                    "",
                    {
                        "progress": "0%",
                        "company_name": "ë¯¸ì…ë ¥",
                        "position": "ë¯¸ì…ë ¥",
                        "resume_analyzed": False,
                        "interview_settings": False,
                        "questions_generated": False,
                        "is_complete": False
                    },
                    gr.update(visible=False),
                    "**ì§„í–‰ë¥ : 0%**\n\n1. â³ ê¸°ë³¸ ì •ë³´ ì…ë ¥\n2. â³ ì´ë ¥ì„œ ë¶„ì„\n3. â³ ì„¤ì • í™•ì •\n4. â³ ì§ˆë¬¸ ìƒì„±\n5. â³ íŒŒì¼ ì €ì¥"
                )
            
            # ì´ë²¤íŠ¸ ì—°ê²°
            send_btn.click(
                send_message,
                [msg, chatbot, file_upload],
                [chatbot, msg, status_display, download_btn, download_status]
            )
            
            msg.submit(
                send_message,
                [msg, chatbot, file_upload],
                [chatbot, msg, status_display, download_btn, download_status]
            )
            
            clear_btn.click(
                clear_chat,
                outputs=[chatbot, msg, status_display, download_btn, download_status]
            )
            
            # í•˜ë‹¨ ì •ë³´
            gr.Markdown("""
            ---
            ### ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì•„í‚¤í…ì²˜
            
            ```
            ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ â†’ ğŸ¤– ëŒ€í™” ë¼ìš°í„° â†’ ğŸ› ï¸ ë„êµ¬ ì‹¤í–‰ â†’ ğŸ“Š ìƒíƒœ ì—…ë°ì´íŠ¸ â†’ ğŸ’¬ ì‘ë‹µ ìƒì„±
                    â†“             â†“              â†“             â†“              â†“
                ë©”ì‹œì§€ ë¶„ì„    ì ì ˆí•œ ë„êµ¬ ì„ íƒ   ì •ë³´ ìˆ˜ì§‘/ì²˜ë¦¬   í”„ë¡œí•„ ì—…ë°ì´íŠ¸   ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
            ```
            
            **ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:**
            - `collect_basic_info`: íšŒì‚¬ëª…, ì§ë¬´, ì›¹ì‚¬ì´íŠ¸ ìˆ˜ì§‘
            - `process_resume_file`: ì´ë ¥ì„œ íŒŒì¼ ë¶„ì„ ë° ì •ë³´ ì¶”ì¶œ
            - `suggest_interview_settings`: ì§ë¬´ë³„ ìµœì  ì„¤ì • ì¶”ì²œ
            - `collect_additional_info`: ì¶”ê°€ ê°œì¸ ì •ë³´ ìˆ˜ì§‘
            - `set_interview_preferences`: ìµœì¢… ë©´ì ‘ ì„¤ì • í™•ì •
            - `generate_personalized_questions`: ê°œì¸ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
            - `save_questions_to_file`: ê²°ê³¼ íŒŒì¼ ì €ì¥
            
            **ğŸ¯ ê¸°ì¡´ ëŒ€ë¹„ ì£¼ìš” ê°œì„ ì‚¬í•­:**
            1. **ë³µì¡í•œ 5íƒ­ UI â†’ ê°„ë‹¨í•œ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**
            2. **ìˆ˜ë™ ì •ë³´ ì…ë ¥ â†’ ìë™ ë¶„ì„ ë° ì¶”ì²œ**
            3. **ì •ì  ì„¤ì • â†’ ë™ì  ì›Œí¬í”Œë¡œìš° ê´€ë¦¬**
            4. **ë‹¨ê³„ë³„ ìˆ˜ë™ ì§„í–‰ â†’ AI ê°€ì´ë“œ ìë™ ì§„í–‰**
            5. **ê¸°ë³¸ ê°œì¸í™” â†’ ì‹¬í™” ê°œì¸í™” (20+ í•„ë“œ)**
            
            ğŸ’¡ **Tip**: ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”! AIê°€ ì•Œì•„ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ìµœì ì˜ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
            """)
        
        return demo


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ LangGraph ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸° ì‹œì‘...")
        
        # í™˜ê²½ ì„¤ì • í™•ì¸
        if not os.getenv("OPENAI_API_KEY"):
            print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            print("   .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_here ì¶”ê°€")
            return
        
        # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        try:
            from langgraph.graph import StateGraph
            from langchain_openai import ChatOpenAI
        except ImportError as e:
            print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {str(e)}")
            print("pip install langgraph langchain-openai pdfplumber python-docx requests beautifulsoup4 ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        
        # ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = Path("temp_downloads")
        temp_dir.mkdir(exist_ok=True)
        print(f"ğŸ“ ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬: {temp_dir.absolute()}")
        
        # ì¸í„°í˜ì´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
        print("ğŸ”„ ê°•í™”ëœ LangGraph ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì¤‘...")
        generator = EnhancedLangGraphInterviewGenerator()
        demo = generator.create_interface()
        
        print("ğŸŒ ì„œë²„ ì‹œì‘ ì¤‘...")
        print("ğŸ’¡ ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:7860 ì„ ì—´ì–´ì£¼ì„¸ìš”.")
        
        demo.launch(
            share=False,
            debug=True,
            server_name="127.0.0.1",
            server_port=7860,
            show_error=True
        )
        
    except ImportError as e:
        print(f"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {str(e)}")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        print("pip install langgraph langchain-openai pdfplumber python-docx requests beautifulsoup4 python-dotenv gradio")
    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        print(f"âŒ ì‹œì‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()