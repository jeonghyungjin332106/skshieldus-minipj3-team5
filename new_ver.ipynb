{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb2a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ë””ë²„ê·¸] ì§ë¬´ëª… ì˜ë¯¸ ìœ ì‚¬ë„: 0.8676\n",
      "\n",
      "[ì¶”ì²œ ì§ë¬´ ë° ìœ ì‚¬ë„]\n",
      "- ë””ì§€í„¸ ë§ˆì¼€í„° (ìœ ì‚¬ë„: 7.1611)\n",
      " ì—­í• : ë””ì§€í„¸ ì±„ë„ì„ í™œìš©í•œ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰, ì†Œì…œ ë¯¸ë””ì–´ ì½˜í…ì¸  ê¸°íš ë° ì œì‘\n",
      " í•„ìš”í•œ ê¸°ìˆ : ì†Œì…œ ë¯¸ë””ì–´ ì½˜í…ì¸  ê¸°íš, ë·°í‹° íŠ¸ë Œë“œ ë¶„ì„, ë°ì´í„° ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë·°í‹° ì‚°ì—… ì´í•´\n",
      " ì¶”ì²œ ì´ìœ : ì´ë ¥ì„œì—ì„œ ì†Œì…œ ë¯¸ë””ì–´ ì½˜í…ì¸  ê¸°íš ë° ì œì‘, ë·°í‹° íŠ¸ë Œë“œ ë¶„ì„, ë°ì´í„° ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë·°í‹° ì‚°ì—… ì´í•´ ë“±ì˜ ì—­ëŸ‰ì„ ë³´ìœ í•˜ê³  ìˆì–´ ë””ì§€í„¸ ë§ˆì¼€í„°ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "- ì½˜í…ì¸  í¬ë¦¬ì—ì´í„° (ìœ ì‚¬ë„: 7.6789)\n",
      " ì—­í• : ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë·°í‹° ì½˜í…ì¸  ê¸°íš, ì´¬ì˜, í¸ì§‘ ë° ì—…ë¡œë“œ\n",
      " í•„ìš”í•œ ê¸°ìˆ : ì½˜í…ì¸  ê¸°íš, ì˜ìƒ ì´¬ì˜ ë° í¸ì§‘, ìœ íŠœë¸Œ ë° ì¸ìŠ¤íƒ€ê·¸ë¨ ì±„ë„ ê´€ë¦¬, ë·°í‹° íŠ¸ë Œë“œ ë¶„ì„, ë·°í‹° ì‚°ì—… ì´í•´\n",
      " ì¶”ì²œ ì´ìœ : ì´ë ¥ì„œì—ì„œ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë·°í‹° ì½˜í…ì¸  ê¸°íš, ì´¬ì˜, í¸ì§‘ ë° ì—…ë¡œë“œ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆì–´ ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "- ë·°í‹° ë¸Œëœë“œ ë§ˆì¼€í„° (ìœ ì‚¬ë„: 7.7435)\n",
      " ì—­í• : ë·°í‹° ë¸Œëœë“œì˜ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰, ë¸Œëœë“œ ë©”ì‹œì§€ ì „ë‹¬\n",
      " í•„ìš”í•œ ê¸°ìˆ : ë¸Œëœë“œ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½, ìŠ¤í† ë¦¬í…”ë§, ë°ì´í„° ê¸°ë°˜ ì½˜í…ì¸  ë¶„ì„, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, ë·°í‹° ì‚°ì—… ì´í•´\n",
      " ì¶”ì²œ ì´ìœ : ì´ë ¥ì„œì—ì„œ ë·°í‹° ë¸Œëœë“œì˜ ë©”ì‹œì§€ë¥¼ ì†Œë¹„ìì˜ ëˆˆë†’ì´ì— ë§ì¶° ìŠ¤í† ë¦¬í…”ë§í•˜ëŠ” ì—­ëŸ‰ì„ ë³´ìœ í•˜ê³  ìˆì–´ ë·°í‹° ë¸Œëœë“œ ë§ˆì¼€í„°ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "\n",
      "[ê´€ì‹¬ ì§ë¬´]: í¬ë¦¬ì—ì´í„°\n",
      "[ê°€ì¥ ìœ ì‚¬í•œ ì¶”ì²œ ì§ë¬´]: ë·°í‹° ë¸Œëœë“œ ë§ˆì¼€í„°\n",
      "[ì½”ë©˜íŠ¸]: 'í¬ë¦¬ì—ì´í„°'ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì§ë¬´ëŠ” 'ë·°í‹° ë¸Œëœë“œ ë§ˆì¼€í„°'ì´ë©° ìœ ì‚¬ë„ëŠ” 7.74ì…ë‹ˆë‹¤.\n",
      "\n",
      "[ğŸ“˜ ê´€ì‹¬ ì§ë¬´ì— í•„ìš”í•œ ê¸°ìˆ  ë° ì„¤ëª…]\n",
      "- ì°½ì˜ì„±: í¬ë¦¬ì—ì´í„°ëŠ” ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ë§Œë“¤ê³  êµ¬í˜„í•´ì•¼ í•˜ë¯€ë¡œ ì°½ì˜ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- ì½˜í…ì¸  ì œì‘ ëŠ¥ë ¥: í¬ë¦¬ì—ì´í„°ëŠ” ë‹¤ì–‘í•œ í˜•íƒœì˜ ì½˜í…ì¸ ë¥¼ ì œì‘í•´ì•¼ í•˜ë¯€ë¡œ ì½˜í…ì¸  ì œì‘ ëŠ¥ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥: í¬ë¦¬ì—ì´í„°ëŠ” ìì‹ ì˜ ì•„ì´ë””ì–´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ê³  í˜‘ì—…ì„ ìœ„í•´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- ê¸°ìˆ ì  ì—­ëŸ‰: í¬ë¦¬ì—ì´í„°ëŠ” ë‹¤ì–‘í•œ ë””ì§€í„¸ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½˜í…ì¸ ë¥¼ ì œì‘í•˜ë¯€ë¡œ ê¸°ìˆ ì  ì—­ëŸ‰ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "- ì‹œê°ì  ê°ê°: í¬ë¦¬ì—ì´í„°ëŠ” ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ì½˜í…ì¸ ë¥¼ ì œì‘í•´ì•¼ í•˜ë¯€ë¡œ ì‹œê°ì  ê°ê°ì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ë¬¸ì„œ íŒŒì‹±\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ìœ ì‚¬ë„\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# ì „ì—­ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ëª¨ë¸ ë¡œë”©\n",
    "name_sim_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "\n",
    "### 1. ì´ë ¥ì„œ íŒŒì‹±\n",
    "def parse_resume(file_path: str) -> str:\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return \"\\n\".join([doc.page_content for doc in texts])\n",
    "\n",
    "\n",
    "### 2. ì¶”ì²œ ì§ë¬´ ìƒì„± (LLM ê¸°ë°˜)\n",
    "job_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì´ë ¥ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì—­ëŸ‰ì— ì í•©í•œ ì§ë¬´ 3~5ê°œë¥¼ ì¶”ì²œí•˜ê³ ,\n",
    "ê° ì§ë¬´ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:\n",
    "\n",
    "1. title: ì§ë¬´ ì´ë¦„\n",
    "2. description: ì§ë¬´ ì£¼ìš” ì—­í•  ì„¤ëª…\n",
    "3. required_skills: í•„ìˆ˜ ê¸°ìˆ  ë˜ëŠ” ì—­ëŸ‰ (ë°°ì—´ë¡œ)\n",
    "4. reason: ì´ ì´ë ¥ì„œì—ì„œ ì´ ì§ë¬´ë¥¼ ì¶”ì²œí•œ ì´ìœ \n",
    "\n",
    "ì´ë ¥ì„œ:\n",
    "---\n",
    "{resume}\n",
    "---\n",
    "ì¶œë ¥ í˜•ì‹:\n",
    "[\n",
    "  {{\n",
    "    \"title\": \"ë°ì´í„° ì—”ì§€ë‹ˆì–´\",\n",
    "    \"description\": \"...\",\n",
    "    \"required_skills\": [\"...\", \"...\"],\n",
    "    \"reason\": \"...\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\"\"\",\n",
    "    input_variables=[\"resume\"]\n",
    ")\n",
    "\n",
    "def recommend_jobs_from_resume(resume_text: str) -> List[Dict]:\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "    prompt = job_prompt_template.format(resume=resume_text)\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        return ast.literal_eval(response.content)\n",
    "    except Exception as e:\n",
    "        print(\"ì¶”ì²œ ì§ë¬´ íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        print(response.content)\n",
    "        return []\n",
    "\n",
    "\n",
    "### 3. ê´€ì‹¬ ì§ë¬´ ë¶„ì„\n",
    "interest_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ë‹¹ì‹ ì€ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì…ë ¥ëœ ê´€ì‹¬ ì§ë¬´ì— ëŒ€í•´, ì´ ì§ë¬´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ í•„ìš”í•œ ê¸°ìˆ  ë˜ëŠ” ì—­ëŸ‰ì„ 5ê°€ì§€ ì´ë‚´ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”. ê° í•­ëª©ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"skill\": \"ê¸°ìˆ  ë˜ëŠ” ì—­ëŸ‰ëª…\",\n",
    "    \"reason\": \"ì™œ ì´ ê¸°ìˆ ì´ í•„ìš”í•œì§€ ì„¤ëª…\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "ê´€ì‹¬ ì§ë¬´:\n",
    "{interest_job}\n",
    "\"\"\",\n",
    "    input_variables=[\"interest_job\"]\n",
    ")\n",
    "\n",
    "def analyze_interest_job(interest_job: str) -> List[Dict[str, str]]:\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "    prompt = interest_prompt_template.format(interest_job=interest_job)\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        return ast.literal_eval(response.content)\n",
    "    except Exception as e:\n",
    "        print(\"ê´€ì‹¬ ì§ë¬´ íŒŒì‹± ì‹¤íŒ¨:\", e)\n",
    "        print(response.content)\n",
    "        return []\n",
    "\n",
    "\n",
    "### 4. ìœ ì‚¬ë„ ê³„ì‚°\n",
    "def compute_similarity_scores(interest_job: str, job_details: List[Dict]) -> List[Dict]:\n",
    "    model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "    pairs = [(interest_job, job[\"title\"]) for job in job_details]\n",
    "    scores = model.predict(pairs)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"title\": job[\"title\"],\n",
    "            \"score\": float(score),\n",
    "            \"description\": job[\"description\"],\n",
    "            \"required_skills\": job[\"required_skills\"],\n",
    "            \"reason\": job[\"reason\"]\n",
    "        }\n",
    "        for job, score in zip(job_details, scores)\n",
    "    ]\n",
    "\n",
    "\n",
    "### 5. ê´€ì‹¬ ì§ë¬´ ìœ íš¨ì„± íŒë‹¨ (LLM)\n",
    "job_validity_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "ì•„ë˜ ì§ë¬´ëª…ì´ ì‹¤ì œ ì‚°ì—…/ì‚¬íšŒì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¼ë°˜ì ì¸ ì§ì—…ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ë¬´ëª…: {job}\n",
    "\n",
    "ì¶œë ¥: \n",
    "- ì¡´ì¬í•˜ëŠ” ì¼ë°˜ì ì¸ ì§ë¬´ë©´ \"ì¡´ì¬í•¨\"\n",
    "- ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ \"ì¡´ì¬í•˜ì§€ ì•ŠìŒ\"\n",
    "\"\"\",\n",
    "    input_variables=[\"job\"]\n",
    ")\n",
    "\n",
    "def is_real_job(job_name: str) -> bool:\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    prompt = job_validity_prompt.format(job=job_name)\n",
    "    response = llm.invoke(prompt).content.strip().lower()\n",
    "    return \"ì¡´ì¬í•¨\" in response\n",
    "\n",
    "\n",
    "### 6. Fallback + ì½”ì‚¬ì¸ ìœ ì‚¬ë„ íŒë‹¨\n",
    "def is_valid_match(best_match: Dict, threshold: float, interest_job: str) -> bool:\n",
    "    if not best_match:\n",
    "        return False\n",
    "    if best_match[\"score\"] < threshold:\n",
    "        return False\n",
    "\n",
    "    emb1 = name_sim_model.encode(interest_job.strip().lower(), convert_to_tensor=True)\n",
    "    emb2 = name_sim_model.encode(best_match[\"title\"].strip().lower(), convert_to_tensor=True)\n",
    "    name_sim = util.cos_sim(emb1, emb2).item()\n",
    "\n",
    "    print(f\"[ë””ë²„ê·¸] ì§ë¬´ëª… ì˜ë¯¸ ìœ ì‚¬ë„: {name_sim:.4f}\")\n",
    "\n",
    "    return name_sim >= 0.6\n",
    "\n",
    "\n",
    "### 7. ì „ì²´ ì‹¤í–‰\n",
    "\n",
    "def analyze_resume_and_match_interest(resume_path: str, interest_job: str) -> Dict:\n",
    "    # ê´€ì‹¬ ì§ë¬´ ìœ íš¨ì„± ë¨¼ì € íŒë‹¨\n",
    "    if not is_real_job(interest_job):\n",
    "        return {\n",
    "            \"recommended_jobs\": [],\n",
    "            \"user_interest\": interest_job,\n",
    "            \"interest_skills\": [],\n",
    "            \"best_match\": None,\n",
    "            \"commentary\": f\"'{interest_job}'ì€(ëŠ”) ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì§ë¬´ì´ê±°ë‚˜ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\"\n",
    "        }\n",
    "\n",
    "    resume_text = parse_resume(resume_path)\n",
    "    job_details = recommend_jobs_from_resume(resume_text)\n",
    "    interest_skills = analyze_interest_job(interest_job)\n",
    "    similarity_scores = compute_similarity_scores(interest_job, job_details)\n",
    "\n",
    "    # ìœ ì‚¬ë„ 0.6 ì´ìƒë§Œ í•„í„°ë§\n",
    "    filtered_scores = [job for job in similarity_scores if job[\"score\"] >= 0.6]\n",
    "    best_match = max(filtered_scores, key=lambda x: x[\"score\"]) if filtered_scores else None\n",
    "    threshold = 0.7\n",
    "\n",
    "    if is_valid_match(best_match, threshold, interest_job):\n",
    "        commentary = f\"'{interest_job}'ì™€ ê°€ì¥ ìœ ì‚¬í•œ ì§ë¬´ëŠ” '{best_match['title']}'ì´ë©° ìœ ì‚¬ë„ëŠ” {best_match['score']:.2f}ì…ë‹ˆë‹¤.\"\n",
    "        match_result = best_match[\"title\"]\n",
    "    else:\n",
    "        commentary = f\"'{interest_job}'ì™€ ìœ ì‚¬í•œ ì§ë¬´ê°€ ëª…í™•íˆ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "        match_result = None\n",
    "\n",
    "    return {\n",
    "        \"recommended_jobs\": filtered_scores,\n",
    "        \"user_interest\": interest_job,\n",
    "        \"interest_skills\": interest_skills,\n",
    "        \"best_match\": match_result,\n",
    "        \"commentary\": commentary\n",
    "    }\n",
    "\n",
    "\n",
    "### 8. ì‹¤í–‰ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸\n",
    "def main():\n",
    "    resume_path = input(\"ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: resume.pdf): \").strip()\n",
    "    interest_job = input(\"ê´€ì‹¬ ì§ë¬´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë°ì´í„° ì—”ì§€ë‹ˆì–´): \").strip()\n",
    "\n",
    "    result = analyze_resume_and_match_interest(resume_path, interest_job)\n",
    "\n",
    "    print(\"\\n[ì¶”ì²œ ì§ë¬´ ë° ìœ ì‚¬ë„]\")\n",
    "    for job in result[\"recommended_jobs\"]:\n",
    "        print(f\"- {job['title']} (ìœ ì‚¬ë„: {job['score']:.4f})\")\n",
    "        print(f\" ì—­í• : {job['description']}\")\n",
    "        print(f\" í•„ìš”í•œ ê¸°ìˆ : {', '.join(job['required_skills'])}\")\n",
    "        print(f\" ì¶”ì²œ ì´ìœ : {job['reason']}\\n\")\n",
    "\n",
    "    print(f\"[ê´€ì‹¬ ì§ë¬´]: {result['user_interest']}\")\n",
    "    print(f\"[ê°€ì¥ ìœ ì‚¬í•œ ì¶”ì²œ ì§ë¬´]: {result['best_match']}\")\n",
    "    print(f\"[ì½”ë©˜íŠ¸]: {result['commentary']}\")\n",
    "\n",
    "    print(f\"\\n[ê´€ì‹¬ ì§ë¬´ì— í•„ìš”í•œ ê¸°ìˆ  ë° ì„¤ëª…]\")\n",
    "    for skill in result[\"interest_skills\"]:\n",
    "        print(f\"- {skill['skill']}: {skill['reason']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-1kfPrwaQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
