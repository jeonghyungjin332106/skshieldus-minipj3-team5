{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa21c9c",
   "metadata": {},
   "source": [
    "### LLM (제가 직접 샘플 넣어서 테스트 해본다고 제가 직접 입력해서 넣는 식으로 작성되어 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a90b10e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ▶ Cross-Encoder best_score: 7.2225\n",
      "\n",
      "=== 분석 결과 ===\n",
      "\n",
      "=== 관심 직무: 품질관리 엔지니어 ===\n",
      "\n",
      "=== 추천 직무 ===\n",
      "1. 품질 관리 엔지니어 - ISO 9001 표준 및 프로세스 개선에 능통한 경험을 토대로 품질 관리 및 프로세스 향상을 담당하는 업무\n",
      "2. 생산 슈퍼바이저 - 생산 일정 및 SOP 문서 작성을 관리하고 MES 지표를 모니터링하여 생산 성과 보고서를 작성하는 업무\n",
      "3. 프로세스 엔지니어 - Lean 및 Six Sigma 프로세스 개선 기술과 SPC를 활용하여 생산 프로세스를 최적화하고 효율성을 향상시키는 업무\n",
      "\n",
      "=== 관심 직무 기술 ===\n",
      "1. 통계 및 데이터 분석 기술: 품질관리 엔지니어는 제품 또는 서비스의 품질을 평가하고 개선하기 위해 데이터를 수집하고 분석해야 합니다. 따라서 통계 및 데이터 분석 기술은 이 직무에서 매우 중요합니다. 이를 통해 문제를 식별하고 해결하는 데 도움이 됩니다.\n",
      "\n",
      "2. 문제 해결 능력: 품질관리 엔지니어는 제품 또는 서비스의 품질 문제를 해결해야 합니다. 이를 위해 문제 해결 능력이 필요하며, 빠르게 문제를 식별하고 효과적인 해결책을 찾아내는 능력이 요구됩니다.\n",
      "\n",
      "3. 품질 관리 도구 활용 능력: 품질관리 엔지니어는 품질을 관리하고 개선하기 위해 다양한 도구를 활용해야 합니다. 이러한 도구에는 통계 소프트웨어, 품질 관리 도구, 테스트 도구 등이 포함될 수 있으며, 이를 효과적으로 활용할 수 있는 능력이 요구됩니다.\n",
      "\n",
      "4. 팀워크 및 커뮤니케이션: 품질관리 엔지니어는 다양한 부서와 협력하여 품질을 개선해야 합니다. 따라서 팀워크 및 커뮤니케이션 능력이 중요하며, 다른 직군과의 원활한 협업을 통해 효율적인 결과를 이끌어내는 능력이 필요합니다.\n",
      "\n",
      "5. 품질 관리 시스템 이해: 품질관리 엔지니어는 품질을 관리하기 위한 시스템을 이해하고 운영해야 합니다. 이를 통해 제품 또는 서비스의 품질을 실시간으로 모니터링하고 개선할 수 있으며, 품질 관리 시스템을 효과적으로 운영하는 능력이 요구됩니다.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# LangChain 모듈 임포트\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# Cross-Encoder 임포트\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 환경변수(OPENAI_API_KEY) 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LLM 및 임베딩 초기화\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "rag_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "# Cross-Encoder 모델 초기화\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# ─── 1. 이력서 텍스트 추출 ───────────────────────────\n",
    "def extract_text_from_file(file_path: Path) -> str:\n",
    "    suffix = file_path.suffix.lower()\n",
    "    if suffix == \".pdf\":\n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "    elif suffix in (\".docx\", \".doc\"):\n",
    "        loader = Docx2txtLoader(str(file_path))\n",
    "    else:\n",
    "        raise ValueError(\"지원 파일 형식은 PDF 또는 DOCX 뿐입니다.\")\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# ─── 2. 벡터스토어 로드/생성 (Ephemeral 모드) ───────────────────────────\n",
    "def get_vectorstore(raw_text: str) -> FAISS:\n",
    "    \"\"\"\n",
    "    매번 새로 FAISS 인메모리 인덱스를 생성합니다.\n",
    "    일회성 분석용으로 디스크에 저장하지 않습니다.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = splitter.split_documents([Document(page_content=raw_text)])\n",
    "    # 인메모리로만 인덱스 생성\n",
    "    vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "    return vectorstore\n",
    "\n",
    "# ─── 3. 통합 분석 프롬프트 & 호출 ─────────────────\n",
    "# 추천 직무 3가지, 각 직무별 설명, 그리고 각 직무의 관련도를 계산한 뒤\n",
    "# 관련도 기준 미만이면 \"관련 직무 없음\" 만 출력, 그렇지 않으면 추천과 기술을 함께 출력합니다.\n",
    "analysis_template = PromptTemplate(\n",
    "    input_variables=[\"resume_content\", \"position\"],\n",
    "    template=\"\"\"\n",
    "당신은 다양한 산업 분야의 커리어 분석 전문가입니다.\n",
    "다음 이력서와 사용자가 입력한 관심 직무명({position})를 바탕으로,\n",
    "아래 세 가지를 수행하세요.\n",
    "\n",
    "—— 입력 데이터 ——\n",
    "이력서 내용:\n",
    "{resume_content}\n",
    "\n",
    "관심 직무: {position}\n",
    "—— 출력 형식 ——\n",
    "1) 경험 기반 추천 직무 3가지 및 각 직무별 설명\n",
    "2) 각 추천 직무가 \"{position}\"과 얼마나 관련 있는지 0.0~1.0 점수로 매기기\n",
    "3) 관련도 점수가 모두 0.3 미만이면, \"관련 직무 없음\" 한 줄만 출력\n",
    "   그렇지 않으면, 1), 2) 결과와 함께\n",
    "   관심 직무({position})에 필요한 핵심 기술 5가지도 한 줄로 나열해 출력\n",
    "\n",
    "(결과는 모두 한국어로 출력)\n",
    "(IT분야가 아닐 수 있습니다. 문서 내용에 기반하여 작성해주세요.)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def analyze_resume_and_position(\n",
    "    raw_text: str,\n",
    "    vectorstore: FAISS,\n",
    "    position: str,\n",
    "    k: int = 4\n",
    ") -> str:\n",
    "    # 벡터스토어를 통한 이력서 청크 생성\n",
    "    docs = vectorstore.similarity_search(\"이력서를 기반으로 수행 가능한 직무를 추론해줘\", k=k)\n",
    "    # 이력서 청크 합치기\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # 통합 프롬프트 호출\n",
    "    prompt = analysis_template.format(\n",
    "        resume_content=context,\n",
    "        position=position\n",
    "    )\n",
    "    return rag_llm.predict(prompt)\n",
    "\n",
    "\n",
    "\n",
    "# ─── 4. 기존 기술 템플릿 및 cross-encoder 로직 제거 ───────────────── 관심 직무 기술 설명 ─────────────────────────\n",
    "skill_template = PromptTemplate(\n",
    "    input_variables=[\"position\"],\n",
    "    template=\"\"\"\n",
    "당신은 커리어 상담 전문가입니다.\n",
    "관심 직무({position})에 필요한 핵심 기술 5가지를 하나씩 나열하고 각 기술에 대한 설명을 덧붙여 주세요.\n",
    "position이 실존하지 않거나 관련 정보가 충분하지 않은 경우, '해당 직무에 대한 정보가 부족합니다.'라고 응답해주세요.\n",
    "IT분야가 아닐 수 있습니다. 문서 내용에 기반하여 작성해주세요.\n",
    "결과는 모두 한국어로 출력해 주세요.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def get_position_skills(position: str) -> str:\n",
    "    prompt = skill_template.format(position=position)\n",
    "    return chat_llm.predict(prompt)\n",
    "\n",
    "# ─── 5. Cross-Encoder relevance 계산 ─────────────────\n",
    "def cross_encoder_score(job: str, position: str) -> float:\n",
    "    # job: 추천 직무명, position: 관심 직무명\n",
    "    return float(cross_encoder.predict([(job, position)])[0])\n",
    "\n",
    "# ─── 6. 최종 분석 함수 ─────────────────────────────\n",
    "recommend_template = PromptTemplate(\n",
    "    input_variables=[\"resume_content\"],\n",
    "    template=\"\"\"\n",
    "당신은 커리어 분석 전문가입니다. 다음 이력서 내용을 기반으로, IT직무에 국한되지 않고\n",
    "지원자가 실제 수행했던 경험, 사용했던 도구, 업무 영역 등을 분석해\n",
    "지원자에게 적합한 추천 직무 3가지와 각 직무에 대한 설명을 출력하세요.\n",
    "(직무명은 현실에서 존재하는 직군으로 명시하세요.)\n",
    "(결과는 한국어로 출력하세요.)\n",
    "\n",
    "이력서:\n",
    "{resume_content}\n",
    "\n",
    "출력 예시:\n",
    "1. [직무명] - [간단한 설명]\n",
    "2. [직무명] - [간단한 설명]\n",
    "3. [직무명] - [간단한 설명]\n",
    "\n",
    "(결과는 한국어로 출력)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def recommend_jobs(vectorstore: FAISS, k: int = 4) -> str:\n",
    "    docs = vectorstore.similarity_search(\"지원자가 수행한 업무 경험, 역량, 도구를 기반으로 추천 직무를 추론해줘\", k=k)\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    prompt = recommend_template.format(resume_content=context)\n",
    "    return rag_llm.predict(prompt)\n",
    "def analyze_resume_and_position(\n",
    "    raw_text: str,\n",
    "    vectorstore: FAISS,\n",
    "    position: str,\n",
    "    k: int = 4,\n",
    "    ce_threshold: float = 6.0\n",
    ") -> str:\n",
    "    # 추천 직무 생성\n",
    "    recommended = recommend_jobs(vectorstore, k=k).strip()\n",
    "\n",
    "    # 추천 직무 라인 파싱\n",
    "    rec_lines = [line.strip() for line in recommended.splitlines() if line.strip().startswith(('1', '2', '3'))]\n",
    "    rec_jobs = [line.split(' ', 1)[1].split(' - ')[0].strip() for line in rec_lines]\n",
    "\n",
    "    # Cross-Encoder로 관련도 측정\n",
    "    scores = [cross_encoder_score(job, position) for job in rec_jobs]\n",
    "    best_score = max(scores) if scores else -float('inf')\n",
    "    print(f\"DEBUG ▶ Cross-Encoder best_score: {best_score:.4f}\")\n",
    "\n",
    "    # 관련도 임계치 미만이면 fallback 메시지 출력\n",
    "    if best_score < ce_threshold:\n",
    "        return \"죄송합니다. 추천 직무와 관심 직무가 의미상 관련이 없어 분석이 어렵습니다.\"\n",
    "\n",
    "    # 관련 있는 경우에만 기술 설명 포함\n",
    "    skills = get_position_skills(position).strip()\n",
    "    result = f\"=== 관심 직무: {position} ===\\n\\n\"\n",
    "    result += \"=== 추천 직무 ===\\n\" + \"\\n\".join(rec_lines) + \"\\n\\n\"\n",
    "    result += \"=== 관심 직무 기술 ===\\n\" + skills\n",
    "    return result\n",
    "\n",
    "\n",
    "# ─── CLI 진입점 ─────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    path = Path(input(\"이력서 파일 경로(.pdf/.docx): \").strip())\n",
    "    resume = extract_text_from_file(path)\n",
    "    vectorstore = get_vectorstore(resume)\n",
    "\n",
    "    position = input(\"관심 직무를 입력하세요 (예: 프론트엔드 개발자): \").strip()\n",
    "    output = analyze_resume_and_position(\n",
    "        resume,\n",
    "        vectorstore,\n",
    "        position,\n",
    "        k=4,\n",
    "        ce_threshold=6.0  # 필요에 따라 조정\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== 분석 결과 ===\\n\")\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c46949",
   "metadata": {},
   "source": [
    "### LangGraph 적용 중 (미완성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db01a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StateGraph.__init__() missing 1 required positional argument: 'state_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(cross_encoder.predict([(job, position)])[\u001b[32m0\u001b[39m])\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# ─── 6. LangGraph 파이프라인 선언 ─────────────────────────\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m g = \u001b[43mStateGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTART\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEND\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# 노드 정의\u001b[39;00m\n\u001b[32m     97\u001b[39m extract_node = Node(name=\u001b[33m\"\u001b[39m\u001b[33mextract\u001b[39m\u001b[33m\"\u001b[39m, fn=extract_text_from_file)\n",
      "\u001b[31mTypeError\u001b[39m: StateGraph.__init__() missing 1 required positional argument: 'state_schema'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# LangChain 모듈 임포트\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# Cross-Encoder 임포트\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# LangGraph 모듈 임포트\n",
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import Literal\n",
    "\n",
    "# 환경변수(OPENAI_API_KEY) 로드\n",
    "load_dotenv()\n",
    "\n",
    "# LLM 및 임베딩 초기화\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "rag_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# ─── 1. 이력서 텍스트 추출 ───────────────────────────\n",
    "def extract_text_from_file(file_path: Path) -> str:\n",
    "    suffix = file_path.suffix.lower()\n",
    "    if suffix == \".pdf\":\n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "    elif suffix in (\".docx\", \".doc\"):\n",
    "        loader = Docx2txtLoader(str(file_path))\n",
    "    else:\n",
    "        raise ValueError(\"지원 파일 형식은 PDF 또는 DOCX 뿐입니다.\")\n",
    "    docs = loader.load()\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# ─── 2. 벡터스토어 생성 (Ephemeral) ───────────────────────────\n",
    "def get_vectorstore(raw_text: str) -> FAISS:\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = splitter.split_documents([Document(page_content=raw_text)])\n",
    "    return FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# ─── 3. 추천 직무 생성 ─────────────────────────────\n",
    "recommend_template = PromptTemplate(\n",
    "    input_variables=[\"resume_content\"],\n",
    "    template=\"\"\"\n",
    "당신은 커리어 분석 전문가입니다. 다음 이력서 내용을 기반으로, IT직무에 국한되지 않고\n",
    "지원자가 실제 수행했던 경험, 사용했던 도구, 업무 영역 등을 분석해\n",
    "지원자에게 적합한 추천 직무 3가지와 각 직무에 대한 설명을 출력하세요.\n",
    "(직무명은 현실에서 존재하는 직군으로 명시하세요.)\n",
    "(결과는 한국어로 출력하세요.)\n",
    "\n",
    "이력서:\n",
    "{resume_content}\n",
    "\n",
    "출력 예시:\n",
    "1. [직무명] - [간단한 설명]\n",
    "2. [직무명] - [간단한 설명]\n",
    "3. [직무명] - [간단한 설명]\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def recommend_jobs(vectorstore: FAISS, k: int = 4) -> list[str]:\n",
    "    docs = vectorstore.similarity_search(\n",
    "        \"지원자가 수행한 업무 경험, 역량, 도구를 기반으로 추천 직무를 추론해줘\", k=k\n",
    "    )\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    text = rag_llm.predict(recommend_template.format(resume_content=context))\n",
    "    # 1. . 2. . 3. 형식으로 반환\n",
    "    return [line.split(' ',1)[1].split(' - ')[0].strip() for line in text.splitlines() if line.strip().startswith(('1','2','3'))]\n",
    "\n",
    "# ─── 4. 관심 직무 기술 생성 ─────────────────────────────\n",
    "skill_template = PromptTemplate(\n",
    "    input_variables=[\"position\"],\n",
    "    template=\"\"\"\n",
    "당신은 커리어 상담 전문가입니다.\n",
    "관심 직무({position})에 필요한 핵심 기술 5가지를 하나씩 나열하고 각 기술에 대한 설명을 덧붙여 주세요.\n",
    "position이 실존하지 않거나 관련 정보가 부족하면 '해당 직무에 대한 정보가 부족합니다.'라고 응답하세요.\n",
    "결과는 모두 한국어로 출력해 주세요.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def get_position_skills(position: str) -> str:\n",
    "    return chat_llm.predict(skill_template.format(position=position))\n",
    "\n",
    "# ─── 5. Cross-Encoder 유사도 계산 ─────────────────────\n",
    "def cross_encoder_score(job: str, position: str) -> float:\n",
    "    return float(cross_encoder.predict([(job, position)])[0])\n",
    "\n",
    "# ─── 6. LangGraph 파이프라인 선언 ─────────────────────────\n",
    "g = StateGraph(start=START, end=END)\n",
    "\n",
    "# 노드 정의\n",
    "extract_node = Node(name=\"extract\", fn=extract_text_from_file)\n",
    "vector_node  = Node(name=\"vectorize\", fn=get_vectorstore)\n",
    "recommend_node= Node(name=\"recommend\", fn=recommend_jobs)\n",
    "score_node    = Node(name=\"score\", fn=lambda rec_jobs, position: [(job, cross_encoder_score(job, position)) for job in rec_jobs])\n",
    "skills_node   = Node(name=\"skills\", fn=get_position_skills)\n",
    "\n",
    "# 그래프 연결\n",
    "# START -> extract\n",
    "g.add_transition(START, extract_node, output_key=\"raw_text\")\n",
    "# extract -> vectorize\n",
    "g.add_transition(extract_node, vector_node, input_key=\"raw_text\", output_key=\"vectorstore\")\n",
    "# vectorize -> recommend\n",
    "g.add_transition(vector_node, recommend_node, input_key=\"vectorstore\", output_key=\"rec_jobs\")\n",
    "# recommend -> score\n",
    "g.add_transition(recommend_node, score_node, input_key=\"rec_jobs\", output_key=\"job_scores\")\n",
    "# recommend -> skills\n",
    "g.add_transition(recommend_node, skills_node, input_key=\"position\", output_key=\"skills\")\n",
    "# score -> END\n",
    "g.add_transition(score_node, END, input_key=\"job_scores\")\n",
    "# skills -> END\n",
    "g.add_transition(skills_node, END, input_key=\"skills\")\n",
    "\n",
    "# ─── 7. 실행 함수 ─────────────────────────────────\n",
    "def run_analysis(resume_path: str, position: str):\n",
    "    inputs = {\n",
    "        \"extract\": {\"file_path\": Path(resume_path)},\n",
    "        \"recommend\": {\"position\": position},\n",
    "        \"score\": {\"position\": position},\n",
    "        \"skills\": {\"position\": position}\n",
    "    }\n",
    "    outputs = g.run(inputs)\n",
    "    rec_jobs    = outputs[END][\"rec_jobs\"]\n",
    "    job_scores  = outputs[END][\"job_scores\"]\n",
    "    skills_text = outputs[END][\"skills\"]\n",
    "\n",
    "    print(f\"=== 관심 직무: {position} ===\")\n",
    "    print(\"=== 추천 직무 및 유사도 ===\")\n",
    "    for job, score in job_scores:\n",
    "        print(f\"- {job} (유사도: {score:.4f})\")\n",
    "    print(\"\\n=== 관심 직무 기술 ===\")\n",
    "    print(skills_text)\n",
    "\n",
    "# ─── CLI 사용 예시 ─────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    path     = input(\"이력서 파일 경로(.pdf/.docx): \")\n",
    "    position = input(\"관심 직무를 입력하세요: \")\n",
    "    run_analysis(path, position)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-1kfPrwaQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
