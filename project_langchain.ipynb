{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d37a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07c0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 유틸\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 문서 로딩 & 전처리\n",
    "from langchain.document_loaders import Docx2txtLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 벡터화 (임베딩) / 검색\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# LLM 모델\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# (만약 Ollama 쓰면)\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 체인 및 에이전트\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.prompts.chat import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 외부 API 호출 등 필요 시\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "759e8ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "llm_model = ChatOllama(model=\"qwen3:1.7b\",temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89fc671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크 개수: 66\n",
      "▶️ AI 답변:\n",
      " 지원자는 디버깅에 대한 기본적인 지식과 BlueJ를 사용한 디버깅 경험을 갖고 있습니다. 이는 백엔드 개발자로서 중요한 기술 중 하나입니다. 디버깅은 코드 작성 중 발생하는 오류를 신속하게 해결하고 효율적인 코드를 작성하는 데 도움이 됩니다. 또한, 중단점 설정, 단계별 코드 실행, 변수 검사 등의 디버깅 기능을 활용하여 코드를 분석하고 수정하는 능력을 갖추고 있습니다.\n",
      "\n",
      "따라서, 백엔드 개발자 포지션에 지원할 때는 이러한 디버깅 기술 및 경험을 강조하여 자신이 문제 해결능력을 갖추고 있다는 것을 강조할 수 있습니다. 또한, BlueJ를 사용한 경험을 통해 새로운 도구나 환경에 빠르게 적응할 수 있는 능력을 갖추고 있다는 것을 언급할 수 있습니다. 이는 백엔드 시스템을 개발하고 유지보수하는 과정에서 중요한 역할을 할 수 있는 기술이며, 지원자의 역량을 강조할 수 있는 요소가 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 2. 문서 로딩 및 분할\n",
    "resume_path = Path(\"./data/tutorial-korean.pdf\")  # sample_resume.pdf 또는 sample_resume.docx 경로 지정\n",
    "\n",
    "# 로더 선택\n",
    "if resume_path.suffix.lower() == \".pdf\":\n",
    "    loader = PyPDFLoader(str(resume_path))\n",
    "else:\n",
    "    loader = Docx2txtLoader(str(resume_path))\n",
    "\n",
    "# 로딩 및 분할\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"분할된 청크 개수: {len(chunks)}\")\n",
    "\n",
    "# 3. 임베딩 및 벡터스토어 구축\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# 4. RetrievalQA 체인 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"아래는 지원자 이력서에서 추출된 정보입니다:\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"위 정보를 참고해, '{question}'에 대해 답변해 주세요.\"\n",
    "    )\n",
    ")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 4}),\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "# 5. 예시 질의\n",
    "question = \"백엔드 개발자 포지션에 지원할 때 강조하면 좋을 기술은 무엇일까?\"\n",
    "answer = qa_chain.run(question)\n",
    "print(\"▶️ AI 답변:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8665dee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, let's tackle this analysis. The user wants me to evaluate the resume entry from the perspective of \"major strengths and areas for improvement.\" \n",
      "\n",
      "First, I need to identify the key points. The resume says \"홍길동, Java/Spring 3년, AWS 배포 경험 있음.\" So, the person has 3 years of Java/Spring experience and some AWS deployment experience.\n",
      "\n",
      "Strengths: The main strengths here are the technical skills in Java and Spring, which are fundamental in the tech industry. The AWS deployment experience is a plus, showing familiarity with cloud services. Also, the resume is concise, which is good for a professional profile.\n",
      "\n",
      "Areas for Improvement: The resume is a bit generic. It doesn't mention specific projects or achievements, which would make it more compelling. The experience is listed as 3 years, but without details, it's hard to quantify the impact. Also, the AWS experience is mentioned but not elaborated on, so there's a gap in showing how they applied their skills. Additionally, the resume doesn't highlight any soft skills or certifications, which are important for a comprehensive profile.\n",
      "\n",
      "I should structure the analysis into strengths and areas for improvement, using bullet points. Make sure to mention the lack of specific details and the need for quantification. Also, note that the resume is concise but could be more detailed to showcase achievements.\n",
      "</think>\n",
      "\n",
      "### 주요 강점과 보완해야 할 부분 분석  \n",
      "\n",
      "#### **주요 강점**  \n",
      "1. **기술적 역량 강조**:  \n",
      "   - **Java/Spring** 기술 스택을 중심으로 3년간의 경험을 보여줌.  \n",
      "   - **AWS 배포 경험**이 있음으로, 클라우드 기반 개발 및 운영 능력이 명확히 반영됨.  \n",
      "   - **직관적인 기술 언어** 사용 (Java/Spring)으로 기술적 지식이 구체적으로 전달됨.  \n",
      "\n",
      "2. **직무 관련성 강조**:  \n",
      "   - **개발 경험**과 **AWS 배포**의 연계성이 높아, 실제 기술 적용 가능성을 높이기 적합.  \n",
      "   - **구체적인 성과** (예: 특정 프로젝트, 성능 개선, 유지보수 등)를 언급하지 않음에도 불구하고, 기술적 역량이 명확히 드러남.  \n",
      "\n",
      "3. **구조적 명확성**:  \n",
      "   - **명확한 정보 기술** (Java/Spring)과 **실무 경험** (AWS 배포)을 구분해, 직무에 맞는 포지션을 명확히 표현 가능.  \n",
      "\n",
      "---\n",
      "\n",
      "#### **보완해야 할 부분**  \n",
      "1. **구체적인 성과 제시**:  \n",
      "   - **기술적 성과** (예: \"Spring Boot 애플리케이션 50% 속도 향상\", \"AWS EC2 클라우드 솔루션 구축\")를 구체화하여, 역량의 실제 적용 가능성 강조.  \n",
      "   - **프로젝트/경험**을 구체화 (예: \"자주 사용한 기술\", \"특정 기술의 적용 사례\")로 보완.  \n",
      "\n",
      "2. **기술적 구체성 강화**:  \n",
      "   - **기술 언어** (Java/Spring)의 구체적인 활용 사례 (예: \"REST API 개발\", \"Spring Security 구현\")를 언급.  \n",
      "   - **AWS 배포**에 대한 구체적인 기술 (예: \"Lambda 함수 배포\", \"CloudFormation 사용\")를 추가.  \n",
      "\n",
      "3. **역량의 체계화**:  \n",
      "   - **기술 역량** (Java/Spring/AWS)과 **실무 역량** (프로젝트 경험, 성과)을 구체적으로 분류하여, 직무에 맞는 포지션을 명확히 표현.  \n",
      "   - **인증/자격** (예: Java 개발자 자격증, AWS Certified Solutions Architect)을 추가하여, 기술적 신뢰도 강화.  \n",
      "\n",
      "4. **구조적 개선**:  \n",
      "   - **기술적 역량**과 **실무 경험**을 구분해, 직무에 맞는 포지션을 명확히 표현.  \n",
      "   - **구체적인 성과** (예: \"3개의 프로젝트 개발\", \"AWS 배포 5개의 서비스\")를 제시하여, 역량의 실제 적용 가능성 강조.  \n",
      "\n",
      "---\n",
      "\n",
      "### 결론  \n",
      "이력서는 기술적 역량과 실무 경험을 명확히 반영할 수 있으며, **기술적 구체성과 성과 제시**가 부족한 점이 있다. **구체적인 프로젝트 사례, 성과, 기술적 구체화**를 추가하면, 직무에 맞는 포지션을 더욱 명확히 전달할 수 있다.\n"
     ]
    }
   ],
   "source": [
    "analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"text_input\", \"analysis_task\"],\n",
    "    template=\"\"\"\n",
    "당신은 전문 텍스트 분석가입니다.\n",
    "아래 주어진 텍스트를 \"{analysis_task}\" 관점에서 자세히 분석해 주세요.\n",
    "\n",
    "––––––––––––––––––––––––––––––\n",
    "{text_input}\n",
    "––––––––––––––––––––––––––––––\n",
    "\n",
    "분석 내용:\n",
    "\"\"\"\n",
    ")\n",
    "prompt = analysis_prompt.format(\n",
    "    text_input=\"이력서: 홍길동, Java/Spring 3년, AWS 배포 경험 있음.\",\n",
    "    analysis_task=\"주요 강점과 보완해야 할 부분\"\n",
    ")\n",
    "response = llm_model.predict(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3c8790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='주어진 이력서를 백엔드 개발자로 평가해보겠습니다.\\n\\n1. **기술 스택**:\\n   - Java와 Spring 프레임워크 경험이 있으므로 백엔드 개발에 필요한 기본적인 기술 스택을 보유하고 있습니다.\\n   - AWS 배포 경험이 있어 클라우드 환경에서의 서비스 배포 및 관리에 대한 이해가 있을 것으로 예상됩니다.\\n\\n2. **경력**:\\n   - 3년간의 Java와 Spring 경력을 보유하고 있어, 실무에서의 경험이 있을 것으로 판단됩니다.\\n\\n3. **부족한 점**:\\n   - 특정 프로젝트나 업무 내용에 대한 구체적인 언급이 없어, 실제 업무에서의 성과나 역량에 대한 정보가 부족합니다.\\n   - 다른 백엔드 기술에 대한 경험이나 지식 여부는 확인되지 않습니다.\\n\\n종합적으로, 이 지원자는 백엔드 개발자로서의 기본적인 기술 스택과 경험을 갖추고 있지만, 보다 구체적인 프로젝트나 역량에 대한 정보가 필요합니다. 추가적인 면접이나 심층적인 이력서 검토를 통해 능력을 더 정확히 평가할 필요가 있습니다.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 423, 'prompt_tokens': 120, 'total_tokens': 543, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--e2f8eb82-c9ae-43da-926e-7fd673027f9c-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "chat_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    streaming=False  # 메시지 리스트 호출 시에는 False 로 두는 게 일반적\n",
    ")\n",
    "\n",
    "analysis_chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 AI 커리어 상담 분야의 전문가입니다. 사용자가 올린 텍스트를 아래 지시대로 분석해 주세요.\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"텍스트:\\n{text_input}\\n\\n분석 관점: {analysis_task}\"\n",
    "    )\n",
    "])\n",
    "messages = analysis_chat_prompt.format_messages(\n",
    "    text_input=\"이력서: 홍길동, Java/Spring 3년, AWS 배포 경험 있음.\",\n",
    "    analysis_task=\"지원 직무(백엔드)와의 적합도 평가\"\n",
    ")\n",
    "response = chat_llm(messages)  # ChatOpenAI.streaming=False 등\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a6ea4",
   "metadata": {},
   "source": [
    "### 이거보시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d981904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "당신은 커리어 상담 전문가입니다.\n",
      "아래 텍스트를 \"가지고 있는 기술 스택들과 커리어 분석\" 관점에서 분석해 주세요.\n",
      "한 문장 씩 줄바꿈해서 출력해주세요.\n",
      "\n",
      "—— 원문 시작 ——\n",
      "John Doe\n",
      "Email: john.doe@example.com | Phone: (123) 456-7890\n",
      "LinkedIn: linkedin.com/in/johndoe\n",
      "Professional Summary\n",
      "Experienced Backend Developer with over 5 years of experience designing and\n",
      "implementing scalable web applications using Java, Spring Boot, and AWS.\n",
      "Passionate about system architecture, performance optimization, and clean code.\n",
      "Experience\n",
      "Senior Backend Developer, TechCorp Inc.\n",
      "- Lead development of microservices architecture using Spring Boot and Docker.\n",
      "- Implemented RESTful APIs consumed by front-end and mobile clients.\n",
      "- Optimized database queries, reducing response time by 30%.\n",
      "Backend Developer, WebSolutions LLC\n",
      "- Developed features for e-commerce platform using Java and Spring MVC.\n",
      "- Collaborated with DevOps to automate CI/CD pipelines on AWS.\n",
      "- Wrote unit and integration tests achieving 85% code coverage.\n",
      "Education\n",
      "B.S. in Computer Science, University of Technology, 2014 - 2018\n",
      "Skills\n",
      "Java, Spring Boot, Docker & Kubernetes, AWS (EC2, S3, RDS), MySQL & PostgreSQL, RESTful APIs, Git &\n",
      "CI/CD, Redis\n",
      "—— 원문 끝 ——\n",
      "\n",
      "분석 결과:\n",
      "\n",
      "지원자는 디버깅에 대한 이해와 경험이 있음을 강조할 수 있습니다. 디버깅은 소프트웨어 개발 과정에서 발생하는 버그를 찾고 해결하는 중요한 역할을 합니다. 이력서에서는 BlueJ를 사용한 디버깅 기능들을 소개하고 있으며, 중단점 설정, 단계별 코드 실행, 변수 검사 등을 간단하게 설명하고 있습니다.\n",
      "\n",
      "따라서, 백엔드 개발자 포지션에 지원할 때는 디버깅 능력을 강조하고, BlueJ를 통해 디버깅을 경험했고 이를 통해 버그를 찾고 해결하는 능력을 갖추고 있다는 점을 강조할 수 있습니다. 또한, 디버깅을 통해 소프트웨어 개발 과정에서 발생하는 문제를 신속하게 해결할 수 있는 능력을 갖추었다는 것을 강조하여 백엔드 개발자로서의 역량을 강조할 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from langchain.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1) 분석용 PromptTemplate 예시\n",
    "analysis_template = PromptTemplate(\n",
    "    input_variables=[\"text_input\", \"analysis_task\"],\n",
    "    template=\"\"\"\n",
    "당신은 커리어 상담 전문가입니다.\n",
    "아래 텍스트를 \"{analysis_task}\" 관점에서 분석해 주세요.\n",
    "한 문장 씩 줄바꿈해서 출력해주세요.\n",
    "\n",
    "—— 원문 시작 ——\n",
    "{text_input}\n",
    "—— 원문 끝 ——\n",
    "\n",
    "분석 결과:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 2) ChatPromptTemplate 예시\n",
    "analysis_chat = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 IT분야 커리어 상담 전문가입니다.\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"다음 텍스트를 \\\"{analysis_task}\\\" 관점에서 분석해 주세요:\\n\\n\"\n",
    "        \"—————\\n\"\n",
    "        \"{text_input}\\n\"\n",
    "        \"—————\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# 3) 파일 → 텍스트 추출 함수\n",
    "def extract_text_from_file(file_path: Path) -> str:\n",
    "    suffix = file_path.suffix.lower()\n",
    "    if suffix == \".pdf\":\n",
    "        loader = PyPDFLoader(str(file_path))\n",
    "    elif suffix in (\".docx\", \".doc\"):\n",
    "        loader = Docx2txtLoader(str(file_path))\n",
    "    else:\n",
    "        raise ValueError(\"PDF 또는 DOCX 파일만 지원합니다.\")\n",
    "    docs = loader.load()\n",
    "    # 여러 페이지/청크를 하나의 문자열로 합치기\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# 4) 최종 프롬프트 생성 함수 (PromptTemplate 버전)\n",
    "def make_analysis_prompt(file_path: Path, analysis_task: str) -> str:\n",
    "    text = extract_text_from_file(file_path)\n",
    "    # 너무 길면 앞뒤만 자르고 중간 생략 처리 가능\n",
    "    if len(text) > 3000:\n",
    "        text = text[:1500] + \"\\n…(생략)…\\n\" + text[-1500:]\n",
    "    return analysis_template.format(\n",
    "        text_input=text,\n",
    "        analysis_task=analysis_task\n",
    "    )\n",
    "\n",
    "# 5) Chat API 호출 예시\n",
    "chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "def run_analysis_via_chat(file_path: Path, analysis_task: str):\n",
    "    text = extract_text_from_file(file_path)\n",
    "    messages = analysis_chat.format_messages(\n",
    "        text_input=text,\n",
    "        analysis_task=analysis_task\n",
    "    )\n",
    "    return chat_llm(messages)\n",
    "\n",
    "# ——— 사용 예 ———\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"./data/a.pdf\")\n",
    "task = \"가지고 있는 기술 스택들과 커리어 분석\"\n",
    "\n",
    "# 1) 단순 문자열 프롬프트 생성\n",
    "prompt_str = make_analysis_prompt(file_path, task)\n",
    "print(prompt_str)\n",
    "\n",
    "# 2) Chat API 호출\n",
    "#response = run_analysis_via_chat(file_path, task)\n",
    "#print(response)\n",
    "response = qa_chain.run(question)   # 혹은 chat_llm(messages).content\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12270429",
   "metadata": {},
   "source": [
    "### LangGraph 건드리는 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4265f8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m graph = StateGraph(state_schema=RAGState)\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 3) 노드 추가 (핸들러는 state를 RAGState로 받아 리턴)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSTART\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33mparse\u001b[39m\u001b[33m\"\u001b[39m, handler=parse_resume)\n\u001b[32m     48\u001b[39m graph.add_node(\u001b[33m\"\u001b[39m\u001b[33membed\u001b[39m\u001b[33m\"\u001b[39m, handler=embed_documents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-basic-ayevwcyA-py3.12\\Lib\\site-packages\\langgraph\\graph\\state.py:373\u001b[39m, in \u001b[36mStateGraph.add_node\u001b[39m\u001b[34m(self, node, action, defer, metadata, input, retry, cache_policy, destinations)\u001b[39m\n\u001b[32m    369\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    370\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNode name must be provided if action is not a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m         )\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes:\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` already present.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1) 핸들러 정의\n",
    "def parse_resume(state):\n",
    "    path = state[\"resume_path\"]\n",
    "    if path.suffix.lower() == \".pdf\":\n",
    "        docs = PyPDFLoader(str(path)).load()\n",
    "    else:\n",
    "        docs = Docx2txtLoader(str(path)).load()\n",
    "    state[\"chunks\"] = RecursiveCharacterTextSplitter(1000,200).split_documents(docs)\n",
    "    return state\n",
    "\n",
    "def embed_documents(state):\n",
    "    emb = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    state[\"vectorstore\"] = FAISS.from_documents(state[\"chunks\"], emb)\n",
    "    return state\n",
    "\n",
    "def run_qa(state):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\",\"question\"],\n",
    "        template=\"이력서 정보:\\n{context}\\n질문: {question}\"\n",
    "    )\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=state[\"vectorstore\"].as_retriever(k=4),\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "    state[\"answer\"] = qa_chain.run(state[\"question\"])\n",
    "    return state\n",
    "\n",
    "# 2) 그래프 구성\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 상태 스키마 정의\n",
    "class RAGState(TypedDict):\n",
    "    resume_path: Path\n",
    "    question: str\n",
    "    chunks: list[Document]\n",
    "    vectorstore: FAISS\n",
    "    answer: str\n",
    "\n",
    "# 2) 스키마를 넘겨서 그래프 생성\n",
    "graph = StateGraph(state_schema=RAGState)\n",
    "\n",
    "# 3) 노드 추가 (핸들러는 state를 RAGState로 받아 리턴)\n",
    "graph.add_node(START)\n",
    "graph.add_node(\"parse\", handler=parse_resume)\n",
    "graph.add_node(\"embed\", handler=embed_documents)\n",
    "graph.add_node(\"qa\", handler=run_qa)\n",
    "graph.add_node(END)\n",
    "\n",
    "graph.add_edge(START, \"parse\")\n",
    "graph.add_edge(\"parse\", \"embed\")\n",
    "graph.add_edge(\"embed\", \"qa\")\n",
    "graph.add_edge(\"qa\", END)\n",
    "\n",
    "# 4) 실행\n",
    "initial_state: RAGState = {\n",
    "    \"resume_path\": Path(\"sample_resume.pdf\"),\n",
    "    \"question\": \"백엔드 지원 시 강조할 기술은?\"\n",
    "}\n",
    "final_state = graph.run(initial_state)\n",
    "print(\"AI 답변:\", final_state[\"answer\"])\n",
    "\n",
    "graph.add_node(START)\n",
    "graph.add_node(\"parse\", handler=parse_resume)\n",
    "graph.add_node(\"embed\", handler=embed_documents)\n",
    "graph.add_node(\"qa\", handler=run_qa)\n",
    "graph.add_node(END)\n",
    "\n",
    "graph.add_edge(START, \"parse\")\n",
    "graph.add_edge(\"parse\", \"embed\")\n",
    "graph.add_edge(\"embed\", \"qa\")\n",
    "graph.add_edge(\"qa\", END)\n",
    "\n",
    "# 3) 실행\n",
    "initial_state = {\n",
    "    \"resume_path\": Path(\"sample_resume.pdf\"),\n",
    "    \"question\": \"백엔드 개발자 지원 시 강조할 기술은?\"\n",
    "}\n",
    "final_state = graph.run(initial_state)\n",
    "print(\"AI 답변:\", final_state[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-ayevwcyA-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
